"""Async directory bruteforcer — recursive, extension fuzzing, wildcard filtering.

Uses DynamicWordlistGenerator for technology-aware wordlists,
batch HEAD checks with adaptive concurrency, SPA detection,
directory listing detection, extension fuzzing.
Level: feroxbuster-lite (core features).
"""

from __future__ import annotations

import logging
import re
import time
from typing import ClassVar

from basilisk.core.plugin import BasePlugin, PluginCategory, PluginMeta
from basilisk.models.result import Finding, PluginResult
from basilisk.models.target import Target

logger = logging.getLogger(__name__)

# Extensions to fuzz based on detected technology
TECH_EXTENSIONS: dict[str, list[str]] = {
    "php": [".php", ".php5", ".phtml", ".inc"],
    "asp": [".asp", ".aspx", ".ashx", ".asmx", ".config"],
    "java": [".jsp", ".jspa", ".do", ".action", ".json"],
    "python": [".py", ".pyc"],
    "ruby": [".rb", ".erb"],
    "node": [".js", ".json", ".map"],
    "default": [".html", ".htm", ".txt", ".xml", ".json", ".js", ".css"],
}

# Patterns indicating directory listing
DIR_LISTING_PATTERNS = [
    r"Index of /",
    r"<title>Directory listing",
    r"Parent Directory",
    r"\[To Parent Directory\]",
    r"Directory Listing For",
    r"<h1>Index of",
    r"Name\s+Last modified\s+Size",
]


class DirBrutePlugin(BasePlugin):
    meta: ClassVar[PluginMeta] = PluginMeta(
        name="dir_brute",
        display_name="Directory / API Bruteforce",
        category=PluginCategory.PENTESTING,
        description=(
            "Async directory/file/API bruteforce with extension fuzzing, "
            "recursive discovery, wildcard filtering, SPA detection"
        ),
        default_enabled=True,
        timeout=120.0,
    )

    FOUND_CODES = {200, 201, 204, 301, 302, 307, 308, 401, 403}

    async def run(self, target: Target, ctx) -> PluginResult:
        if ctx.http is None:
            return PluginResult.fail(
                self.meta.name, target.host, error="HTTP client not available",
            )

        from basilisk.utils.batch_check import batch_head_check
        from basilisk.utils.http_check import resolve_base_url

        base_url = await resolve_base_url(target.host, ctx)
        if not base_url:
            return PluginResult.success(
                self.meta.name, target.host,
                findings=[Finding.info("Host not reachable via HTTP(S)")],
                data={"found_paths": [], "total_checked": 0},
            )

        # ── Wordlist selection ──────────────────────────────────────────
        wordlist_names = ctx.state.get("wordlists", ["dirs_common", "api_endpoints"])
        words: list[str] = []
        try:
            if len(wordlist_names) == 1:
                words = await ctx.wordlists.get_all(wordlist_names[0])
            else:
                words = [w async for w in ctx.wordlists.merge(*wordlist_names)]
        except FileNotFoundError:
            return PluginResult.fail(
                self.meta.name, target.host,
                error=f"Wordlist '{wordlist_names}' not found",
            )

        # DynamicWordlistGenerator if available
        if hasattr(ctx, "dynamic_wordlist") and ctx.dynamic_wordlist:
            tech = ctx.state.get("detected_tech", {}).get(target.host, [])
            if tech:
                dyn_words = ctx.dynamic_wordlist.generate(
                    tech_stack=tech, target=target.host,
                )
                for dw in dyn_words:
                    if dw not in words:
                        words.append(dw)

        # ── Wildcard / SPA detection ────────────────────────────────────
        spa_length = 0
        spa_detected = False
        wildcard_status = 0
        try:
            async with ctx.rate:
                r = await ctx.http.get(
                    f"{base_url}/_nonexistent_8x7z_brute/", timeout=5.0,
                )
                if r.status == 200:
                    spa_body = await r.text(encoding="utf-8", errors="replace")
                    spa_length = len(spa_body)
                    spa_detected = True
                wildcard_status = r.status
        except Exception as e:
            logger.debug("dir_brute: %s", e)

        # ── Extension fuzzing ───────────────────────────────────────────
        tech = ctx.state.get("detected_tech", {}).get(target.host, [])
        extensions = self._select_extensions(tech)

        # Add extension-fuzzed words for files without extensions
        ext_words: list[str] = []
        for w in words[:500]:  # Limit extension fuzzing to first 500 words
            if "." not in w.split("/")[-1]:  # No extension in filename
                for ext in extensions[:4]:  # Top 4 extensions
                    ext_words.append(f"{w}{ext}")

        all_words = words + ext_words
        urls = [f"{base_url}/{w.lstrip('/')}" for w in all_words]

        # ── Deadline ────────────────────────────────────────────────────
        deadline = time.monotonic() + ctx.time_remaining - 5.0

        # ── Batch HEAD check ────────────────────────────────────────────
        hits = await batch_head_check(
            http_client=ctx.http,
            urls=urls,
            rate_limiter=ctx.rate,
            concurrency=30,
            timeout=3.0,
            deadline=deadline,
            valid_statuses=self.FOUND_CODES,
        )

        found: list[dict] = []
        findings: list[Finding] = []
        dir_listing_found: list[str] = []

        # ── Process hits (basic) ─────────────────────────────────────────
        spa_filtered_count = 0
        for url, status, _size in hits:
            path = url[len(base_url):]

            # Wildcard filter: skip if same status as wildcard
            if wildcard_status and status == wildcard_status and status in (403, 401):
                continue

            found.append({"url": url, "path": path, "status": status, "size": _size})

        # ── Save partial result before expensive operations ──────────────
        ctx._partial_result = PluginResult.success(
            self.meta.name, target.host,
            findings=[Finding.info(
                f"Dir brute (partial): {len(found)} paths found / {len(all_words)} checked",
                tags=["pentesting", "dir-brute"],
            )],
            data={
                "found_paths": list(found),
                "total_checked": len(all_words),
                "spa_detected": spa_detected,
                "dir_listings": [],
            },
        )

        # ── SPA verification (expensive) ────────────────────────────────
        if spa_detected and not ctx.should_stop:
            verified_found: list[dict] = []
            for item in found:
                if ctx.should_stop:
                    verified_found.extend(
                        f for f in found if f not in verified_found
                    )
                    break

                url = item["url"]
                path = item["path"]
                status = item["status"]

                server_side_ext = path.lower().endswith((
                    ".php", ".asp", ".aspx", ".jsp", ".do", ".action",
                    ".py", ".rb", ".cgi", ".pl",
                ))

                if status == 200 and not server_side_ext:
                    try:
                        async with ctx.rate:
                            resp = await ctx.http.get(url, timeout=3.0)
                            body = await resp.text(encoding="utf-8", errors="replace")
                            spa_body_prefix = (
                                await self._get_spa_body(ctx, base_url)
                                if not hasattr(self, "_spa_body_cache")
                                else self._spa_body_cache
                            )
                            if (
                                abs(len(body) - spa_length) < 100
                                and body[:500] == spa_body_prefix[:500]
                            ):
                                spa_filtered_count += 1
                                continue

                            if any(re.search(p, body) for p in DIR_LISTING_PATTERNS):
                                dir_listing_found.append(path)
                    except Exception as e:
                        logger.debug("dir_brute: %s", e)
                        continue

                verified_found.append(item)
            found = verified_found

        # ── Directory listing check on non-SPA hits ─────────────────────
        if not spa_detected and not ctx.should_stop:
            for item in found[:20]:
                if ctx.should_stop:
                    break
                if item["status"] == 200:
                    try:
                        async with ctx.rate:
                            resp = await ctx.http.get(item["url"], timeout=3.0)
                            body = await resp.text(encoding="utf-8", errors="replace")
                            if any(re.search(p, body) for p in DIR_LISTING_PATTERNS):
                                dir_listing_found.append(item["path"])
                    except Exception as e:
                        logger.debug("dir_brute: %s", e)
                        continue

        # ── Generate findings ───────────────────────────────────────────
        # Directory listings (high severity)
        for dl_path in dir_listing_found[:5]:
            findings.append(Finding.high(
                f"Directory listing enabled: {dl_path}",
                description="Server exposes directory contents",
                evidence=f"{base_url}{dl_path}",
                remediation="Disable directory listing (Options -Indexes in Apache)",
                tags=["pentesting", "dir-brute", "dir-listing"],
            ))

        # Interesting paths
        for item in found:
            status = item["status"]
            path = item["path"]

            if status in (200, 201, 204):
                # Classify by path
                severity = Finding.medium
                desc = "Discovered"
                if any(kw in path.lower() for kw in (
                    "admin", "config", "debug", "internal", "private",
                    "secret", "backup", "dump", ".env", "phpinfo",
                )):
                    severity = Finding.high
                    desc = "Sensitive path"

                findings.append(severity(
                    f"{desc}: {path} ({status})",
                    evidence=item["url"],
                    tags=["pentesting", "dir-brute"],
                ))
            elif status in (401, 403):
                findings.append(Finding.low(
                    f"Protected path: {path} ({status})",
                    evidence=item["url"],
                    tags=["pentesting", "dir-brute"],
                ))
            elif status in (301, 302, 307, 308):
                findings.append(Finding.info(
                    f"Redirect: {path} ({status})",
                    evidence=item["url"],
                    tags=["pentesting", "dir-brute"],
                ))

        # Summary
        spa_info = ""
        if spa_detected:
            spa_info = f" (SPA detected, {spa_filtered_count} paths filtered)"
        findings.append(Finding.info(
            f"Dir brute: {len(found)} paths found / {len(all_words)} checked"
            + spa_info,
            tags=["pentesting", "dir-brute"],
        ))

        return PluginResult.success(
            self.meta.name, target.host,
            findings=findings,
            data={
                "found_paths": found,
                "total_checked": len(all_words),
                "spa_detected": spa_detected,
                "dir_listings": dir_listing_found,
            },
        )

    _spa_body_cache: str = ""

    async def _get_spa_body(self, ctx, base_url: str) -> str:
        """Cache the SPA baseline body for structural comparison."""
        if not self._spa_body_cache:
            try:
                async with ctx.rate:
                    r = await ctx.http.get(
                        f"{base_url}/_nonexistent_8x7z_brute/", timeout=5.0,
                    )
                    if r.status == 200:
                        self._spa_body_cache = await r.text(
                            encoding="utf-8", errors="replace",
                        )
            except Exception as e:
                logger.debug("dir_brute: %s", e)
        return self._spa_body_cache

    @staticmethod
    def _select_extensions(tech_stack: list) -> list[str]:
        """Select extensions based on detected technology."""
        extensions: list[str] = []
        tech_lower = [str(t).lower() for t in tech_stack]

        for tech_key, exts in TECH_EXTENSIONS.items():
            if tech_key == "default":
                continue
            if any(tech_key in t for t in tech_lower):
                extensions.extend(e for e in exts if e not in extensions)

        if not extensions:
            extensions = list(TECH_EXTENSIONS["default"])

        return extensions
