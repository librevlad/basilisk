"""Spring Boot Actuator & debug endpoint exploitation."""

from __future__ import annotations

import json
import re
from typing import ClassVar

from basilisk.core.plugin import BasePlugin, PluginCategory, PluginMeta
from basilisk.models.result import Finding, PluginResult
from basilisk.models.target import Target

SENSITIVE_ENV_KEYS = [
    # Generic sensitive patterns
    "password", "secret", "key", "token", "credential",
    "database", "db_url", "api_key", "private",
    "jwt_secret", "session_secret",
    # AWS
    "aws_access_key_id", "aws_secret_access_key",
    "aws_session_token", "aws_",
    # Azure
    "azure_client_secret", "azure_client_id",
    "azure_tenant_id",
    # GCP
    "gcp_service_account", "google_application_credentials",
    # Database URLs and credentials
    "jdbc_url", "spring_datasource_url",
    "spring_datasource_password", "spring_datasource_username",
    "redis_url", "redis_password", "redis",
    "mongo_uri", "mongodb_uri", "mongo",
    "elasticsearch_url", "elasticsearch_password",
    # Message queues
    "rabbitmq_default_pass", "rabbitmq_password",
    "kafka_password",
    # Mail / SMTP
    "smtp_password", "mail_password",
    # Third-party services
    "sendgrid_api_key", "stripe_secret_key",
    "github_token", "gitlab_token", "slack_token",
    "twilio_auth_token",
    # Secrets management
    "vault_token", "vault_addr",
    # Crypto / signing
    "jwt_secret", "encryption_key", "signing_key",
    "hmac_secret", "aes_key",
]

ACTUATOR_ENDPOINTS = [
    ("/actuator/env", "env"),
    ("/env", "env"),
    ("/actuator/mappings", "mappings"),
    ("/mappings", "mappings"),
    ("/actuator/beans", "beans"),
    ("/actuator/health", "health"),
    ("/actuator/configprops", "configprops"),
    ("/actuator/info", "info"),
    ("/actuator/metrics", "metrics"),
    ("/metrics", "prometheus"),
    ("/actuator/scheduledtasks", "scheduledtasks"),
    ("/actuator/sessions", "sessions"),
    ("/actuator/shutdown", "shutdown"),
    ("/actuator/threaddump", "threaddump"),
    ("/actuator/heapdump", "heapdump"),
    ("/actuator/logfile", "logfile"),
    ("/actuator/loggers", "loggers"),
    ("/actuator/auditevents", "auditevents"),
    ("/actuator/caches", "caches"),
    ("/actuator/conditions", "conditions"),
    ("/actuator/flyway", "flyway"),
    ("/actuator/liquibase", "liquibase"),
    ("/actuator/prometheus", "prometheus"),
    ("/actuator/quartz", "quartz"),
    ("/actuator/startup", "startup"),
    ("/actuator/gateway/routes", "gateway"),
    ("/actuator/refresh", "refresh"),
    ("/actuator/restart", "restart"),
    ("/actuator/jolokia", "jolokia"),
    ("/actuator/trace", "trace"),
    ("/actuator/httptrace", "httptrace"),
]

OPENAPI_PATHS = [
    "/swagger-ui.html",
    "/swagger-ui/",
    "/swagger-ui/index.html",
    "/v2/api-docs",
    "/v3/api-docs",
    "/api-docs",
    "/swagger.json",
    "/swagger.yaml",
    "/swagger-resources",
    "/swagger/v1/swagger.json",
    "/api/swagger-ui.html",
    "/api/v1/swagger-ui.html",
    "/api/swagger.json",
    "/docs",
    "/redoc",
    "/openapi.json",
    "/openapi.yaml",
    "/.well-known/openapi",
    "/graphql",
    "/graphiql",
    "/altair",
    "/playground",
]

GRAPHQL_PATHS = [
    "/graphql",
    "/graphiql",
    "/altair",
    "/playground",
    "/api/graphql",
    "/v1/graphql",
    "/v2/graphql",
    "/query",
    "/gql",
    "/graphql/console",
    "/graphql/schema",
    "/.well-known/graphql",
    "/api/v1/graphql",
    "/graph",
    "/graphql/explorer",
]

INTROSPECTION_QUERY = '{"query":"{__schema{types{name,fields{name}}}}"}'


class ActuatorExploitPlugin(BasePlugin):
    meta: ClassVar[PluginMeta] = PluginMeta(
        name="actuator_exploit",
        display_name="Actuator Exploitation",
        category=PluginCategory.PENTESTING,
        description="Exploits Spring Boot Actuator, Swagger/OpenAPI, and GraphQL endpoints",
        depends_on=["debug_endpoints"],
        produces=["actuator_findings"],
        timeout=60.0,
    )

    async def run(self, target: Target, ctx) -> PluginResult:
        if ctx.http is None:
            return PluginResult.fail(
                self.meta.name, target.host, error="HTTP client not available"
            )

        findings: list[Finding] = []
        from basilisk.utils.http_check import resolve_base_url

        base_url = await resolve_base_url(target.host, ctx)
        if not base_url:
            return PluginResult.success(
                self.meta.name, target.host,
                findings=[Finding.info("Host not reachable")],
                data={"actuator": {}},
            )

        act_data: dict = {
            "env_secrets": [], "mappings": [], "beans_count": 0,
            "api_endpoints": [], "graphql_types": [],
        }

        # 1. Actuator endpoints
        seen_types: set[str] = set()
        for path, etype in ACTUATOR_ENDPOINTS:
            if etype in seen_types:
                continue

            url = f"{base_url}{path}"
            try:
                async with ctx.rate:
                    resp = await ctx.http.get(url, timeout=8.0)
                    if resp.status != 200:
                        continue
                    body = await resp.text(encoding="utf-8", errors="replace")
                    if not body or len(body) < 5:
                        continue
            except Exception:
                continue

            seen_types.add(etype)

            if etype == "env":
                await self._parse_env(body, url, findings, act_data)
            elif etype == "mappings":
                await self._parse_mappings(body, url, findings, act_data)
            elif etype == "beans":
                self._parse_beans(body, url, findings, act_data)
            elif etype == "health":
                self._parse_health(body, url, findings)
            elif etype == "configprops":
                self._parse_configprops(body, url, findings, act_data)
            elif etype in ("metrics", "prometheus"):
                self._parse_metrics(body, url, etype, findings)

        # 2. Swagger / OpenAPI
        await self._check_openapi(base_url, ctx, findings, act_data)

        # 3. GraphQL introspection
        await self._check_graphql(base_url, ctx, findings, act_data)

        if not findings:
            findings.append(Finding.info(
                "No exploitable actuator/debug endpoints found",
                tags=["pentesting", "actuator"],
            ))

        return PluginResult.success(
            self.meta.name, target.host,
            findings=findings,
            data={"actuator": act_data},
        )

    async def _parse_env(
        self, body: str, url: str, findings: list[Finding], data: dict,
    ) -> None:
        """Extract sensitive keys from /actuator/env."""
        try:
            env_json = json.loads(body)
        except (json.JSONDecodeError, ValueError):
            return

        secrets_found: list[str] = []

        # Walk through propertySources
        sources = env_json.get("propertySources", [])
        for source in sources:
            props = source.get("properties", {})
            for key, val_obj in props.items():
                key_lower = key.lower()
                for sensitive in SENSITIVE_ENV_KEYS:
                    if sensitive in key_lower:
                        value = val_obj.get("value", "******")
                        secrets_found.append(f"{key}={value}")
                        break

        if secrets_found:
            data["env_secrets"] = secrets_found[:20]
            findings.append(Finding.critical(
                f"Actuator /env exposes {len(secrets_found)} secrets",
                description=(
                    "Spring Boot Actuator environment endpoint exposes "
                    "sensitive configuration including passwords and API keys"
                ),
                evidence=f"URL: {url}\nSecrets: {'; '.join(secrets_found[:5])}...",
                remediation=(
                    "Disable /actuator/env in production. Use Spring Security "
                    "to restrict actuator endpoints."
                ),
                tags=["pentesting", "actuator", "secrets"],
            ))
        else:
            findings.append(Finding.medium(
                "Actuator /env accessible (no secrets detected)",
                evidence=url,
                remediation="Restrict actuator endpoints to authenticated users",
                tags=["pentesting", "actuator"],
            ))

    async def _parse_mappings(
        self, body: str, url: str, findings: list[Finding], data: dict,
    ) -> None:
        """Extract URL routes from /actuator/mappings."""
        try:
            mappings_json = json.loads(body)
        except (json.JSONDecodeError, ValueError):
            return

        routes: list[str] = []

        # Spring Boot 2.x format
        contexts = mappings_json.get("contexts", {})
        for _ctx_name, ctx_data in contexts.items():
            dispatcher = ctx_data.get("mappings", {}).get(
                "dispatcherServlets", {},
            )
            for _servlet_name, handlers in dispatcher.items():
                for handler in handlers:
                    patterns = handler.get("predicate", "")
                    if patterns:
                        routes.append(patterns)

        # Spring Boot 1.x format fallback
        if not routes and isinstance(mappings_json, list):
            for entry in mappings_json:
                path = entry.get("path", "")
                if path:
                    routes.append(path)

        if routes:
            data["mappings"] = routes[:50]
            admin_routes = [
                r for r in routes
                if any(
                    kw in r.lower()
                    for kw in ("admin", "internal", "private", "manage")
                )
            ]
            findings.append(Finding.high(
                f"Actuator /mappings exposes {len(routes)} routes",
                description=(
                    f"All application URL routes disclosed. "
                    f"Admin/internal routes: {len(admin_routes)}"
                ),
                evidence=(
                    f"URL: {url}\n"
                    f"Sample routes: {'; '.join(routes[:10])}\n"
                    f"Admin routes: {'; '.join(admin_routes[:5])}"
                ),
                remediation="Restrict /actuator/mappings to authenticated users",
                tags=["pentesting", "actuator", "recon"],
            ))

    def _parse_beans(
        self, body: str, url: str, findings: list[Finding], data: dict,
    ) -> None:
        """Count Spring beans and identify frameworks."""
        try:
            beans_json = json.loads(body)
        except (json.JSONDecodeError, ValueError):
            return

        bean_count = 0
        contexts = beans_json.get("contexts", {})
        for ctx_data in contexts.values():
            bean_count += len(ctx_data.get("beans", {}))

        data["beans_count"] = bean_count
        if bean_count > 0:
            findings.append(Finding.medium(
                f"Actuator /beans discloses {bean_count} Spring beans",
                evidence=url,
                remediation="Restrict /actuator/beans",
                tags=["pentesting", "actuator"],
            ))

    def _parse_health(
        self, body: str, url: str, findings: list[Finding],
    ) -> None:
        """Parse health check details."""
        try:
            health = json.loads(body)
        except (json.JSONDecodeError, ValueError):
            return

        components = health.get("components", {})
        db_info = components.get("db", {}).get("details", {})
        if db_info:
            findings.append(Finding.medium(
                "Actuator /health exposes database details",
                evidence=f"URL: {url}\nDB: {json.dumps(db_info)[:200]}",
                remediation="Set management.endpoint.health.show-details=never",
                tags=["pentesting", "actuator"],
            ))

    def _parse_configprops(
        self, body: str, url: str, findings: list[Finding], data: dict,
    ) -> None:
        """Check configprops for sensitive values."""
        try:
            json.loads(body)
        except (json.JSONDecodeError, ValueError):
            return

        findings.append(Finding.high(
            "Actuator /configprops accessible",
            description="Application configuration properties exposed",
            evidence=f"URL: {url}\nSize: {len(body)} bytes",
            remediation="Restrict /actuator/configprops in production",
            tags=["pentesting", "actuator", "config"],
        ))

    def _parse_metrics(
        self, body: str, url: str, etype: str, findings: list[Finding],
    ) -> None:
        """Parse Prometheus or Spring metrics."""
        if etype == "prometheus":
            # Prometheus text format
            metric_names = re.findall(r"^([a-z_]+)\{", body, re.MULTILINE)
            unique = set(metric_names)
            findings.append(Finding.medium(
                f"Prometheus metrics exposed ({len(unique)} metric types)",
                evidence=f"URL: {url}\nSample: {', '.join(list(unique)[:10])}",
                remediation="Restrict /metrics to monitoring infrastructure only",
                tags=["pentesting", "actuator", "metrics"],
            ))
        else:
            # Spring actuator /metrics
            try:
                metrics = json.loads(body)
                names = metrics.get("names", [])
                findings.append(Finding.medium(
                    f"Actuator /metrics exposes {len(names)} metrics",
                    evidence=f"URL: {url}\nMetrics: {', '.join(names[:10])}",
                    remediation="Restrict /actuator/metrics",
                    tags=["pentesting", "actuator", "metrics"],
                ))
            except (json.JSONDecodeError, ValueError):
                pass

    async def _check_openapi(
        self, base_url: str, ctx, findings: list[Finding], data: dict,
    ) -> None:
        """Download and parse Swagger/OpenAPI specifications."""
        for path in OPENAPI_PATHS:
            url = f"{base_url}{path}"
            try:
                async with ctx.rate:
                    resp = await ctx.http.get(url, timeout=8.0)
                    if resp.status != 200:
                        continue
                    body = await resp.text(encoding="utf-8", errors="replace")
            except Exception:
                continue

            try:
                spec = json.loads(body)
            except (json.JSONDecodeError, ValueError):
                continue

            # Extract endpoints
            paths = spec.get("paths", {})
            api_endpoints: list[dict] = []
            unauth_endpoints: list[str] = []

            for endpoint_path, methods in paths.items():
                for method, details in methods.items():
                    if method in ("get", "post", "put", "delete", "patch"):
                        ep = {"path": endpoint_path, "method": method.upper()}
                        api_endpoints.append(ep)

                        # Check for missing security
                        security = details.get("security", None)
                        if security is not None and len(security) == 0:
                            unauth_endpoints.append(
                                f"{method.upper()} {endpoint_path}"
                            )

            if api_endpoints:
                data["api_endpoints"] = api_endpoints[:100]
                findings.append(Finding.high(
                    f"OpenAPI spec exposes {len(api_endpoints)} API endpoints",
                    description=(
                        f"Full API documentation accessible. "
                        f"Unauthenticated endpoints: {len(unauth_endpoints)}"
                    ),
                    evidence=(
                        f"URL: {url}\n"
                        f"Total: {len(api_endpoints)} endpoints\n"
                        f"Unauth: {'; '.join(unauth_endpoints[:5])}"
                    ),
                    remediation="Restrict API docs to dev/staging environments",
                    tags=["pentesting", "actuator", "api"],
                ))
                return  # Found one spec, enough

    async def _check_graphql(
        self, base_url: str, ctx, findings: list[Finding], data: dict,
    ) -> None:
        """Attempt GraphQL introspection."""
        for path in GRAPHQL_PATHS:
            url = f"{base_url}{path}"
            try:
                async with ctx.rate:
                    resp = await ctx.http.post(
                        url,
                        data=INTROSPECTION_QUERY,
                        headers={"Content-Type": "application/json"},
                        timeout=10.0,
                    )
                    if resp.status != 200:
                        continue
                    body = await resp.text(encoding="utf-8", errors="replace")
            except Exception:
                continue

            try:
                result = json.loads(body)
            except (json.JSONDecodeError, ValueError):
                continue

            schema = result.get("data", {}).get("__schema", {})
            types = schema.get("types", [])
            if not types:
                continue

            # Filter out built-in types
            custom_types = [
                t for t in types
                if not t.get("name", "").startswith("__")
            ]
            type_names = [t.get("name", "") for t in custom_types]
            data["graphql_types"] = type_names[:50]

            # Look for sensitive types
            sensitive = [
                n for n in type_names
                if any(
                    kw in n.lower()
                    for kw in ("user", "admin", "auth", "token", "secret", "password")
                )
            ]

            findings.append(Finding.high(
                f"GraphQL introspection enabled ({len(custom_types)} types)",
                description=(
                    f"Full schema exposed. "
                    f"Sensitive types: {', '.join(sensitive) or 'none detected'}"
                ),
                evidence=(
                    f"URL: {url}\n"
                    f"Types: {', '.join(type_names[:15])}\n"
                    f"Sensitive: {', '.join(sensitive[:5])}"
                ),
                remediation="Disable GraphQL introspection in production",
                tags=["pentesting", "actuator", "graphql"],
            ))
            return  # Found one endpoint, enough
