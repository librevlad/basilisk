"""Hidden parameter discovery â€” arjun-style diff-based parameter brute-force.

Discovers hidden/undocumented parameters on web endpoints by:
1. Capturing baseline response
2. Injecting candidate param names and comparing via ResponseDiffer
3. Mining param names from HTML comments, JS variables, error messages
4. Using OpenAPI spec params from pipeline when available
"""

from __future__ import annotations

import re
from typing import ClassVar

from basilisk.core.plugin import BasePlugin, PluginCategory, PluginMeta
from basilisk.models.result import Finding, PluginResult
from basilisk.models.target import Target

# Common hidden parameter names (500+ entries)
COMMON_PARAMS: list[str] = [
    # Auth & session
    "id", "uid", "user_id", "userid", "user", "username", "login", "email",
    "password", "passwd", "pass", "token", "auth", "api_key", "apikey",
    "key", "secret", "session", "sid", "csrf", "csrf_token", "nonce",
    "access_token", "refresh_token", "jwt", "bearer",
    # IDOR targets
    "account", "account_id", "profile", "profile_id", "order", "order_id",
    "invoice", "invoice_id", "transaction", "transaction_id",
    "customer", "customer_id", "client", "client_id",
    "doc", "doc_id", "document", "document_id",
    "file", "file_id", "filename", "filepath", "path",
    "record", "record_id", "item", "item_id", "product", "product_id",
    # Navigation & filtering
    "page", "p", "limit", "offset", "skip", "count", "size", "per_page",
    "sort", "orderby", "sort_by", "direction", "dir",
    "filter", "search", "q", "query", "keyword", "s", "term",
    "category", "cat", "type", "status", "state", "role",
    "lang", "language", "locale", "l", "hl",
    # Injection targets
    "url", "uri", "link", "href", "src", "source", "dest", "destination",
    "redirect", "redirect_url", "redirect_uri", "return", "return_url",
    "next", "next_url", "goto", "to", "target", "rurl", "continue",
    "callback", "callback_url", "ref", "referer", "referrer",
    "template", "tpl", "theme", "view", "layout", "render",
    "include", "require", "import", "load", "read", "fetch",
    "cmd", "command", "exec", "execute", "run", "do", "action",
    "module", "mod", "plugin", "component", "controller", "handler",
    "method", "func", "function", "op", "operation",
    # Data formats
    "format", "output", "response", "content_type", "accept",
    "encoding", "charset", "mime",
    "json", "xml", "csv", "html", "text", "raw",
    # Debug / internal
    "debug", "test", "verbose", "trace", "log", "dev", "mode",
    "version", "v", "env", "environment", "config", "settings",
    "admin", "internal", "private", "hidden",
    "preview", "draft", "beta", "staging",
    # File operations
    "upload", "download", "export", "backup",
    "attachment", "media", "image", "img", "photo", "avatar",
    "file_type", "ext", "extension",
    # API-specific
    "fields", "select", "expand", "include_fields", "exclude",
    "populate", "embed", "depth", "level", "recursive",
    "with", "relations", "join",
    "start_date", "end_date", "date", "from", "since", "until",
    "min", "max", "range", "between",
    "group", "group_by", "aggregate", "sum", "avg",
    # Headers as params (some apps read from query)
    "x-forwarded-for", "x-real-ip", "x-original-url",
    "x-rewrite-url", "x-custom-ip-authorization",
    # Misc
    "name", "title", "description", "comment", "message", "body",
    "content", "data", "value", "payload",
    "tag", "tags", "label", "labels",
    "ip", "host", "hostname", "domain", "port",
    "width", "height", "color", "style",
    "jsonp", "padding",
    "scope", "permission", "permissions", "access",
    "enabled", "disabled", "active", "inactive",
    "allow", "deny", "block", "whitelist", "blacklist",
]

# Batch size for concurrent parameter testing
BATCH_SIZE = 15

# Max parameters to find before stopping
MAX_FOUND = 30


class ParamDiscoverPlugin(BasePlugin):
    meta: ClassVar[PluginMeta] = PluginMeta(
        name="param_discover",
        display_name="Parameter Discovery",
        category=PluginCategory.PENTESTING,
        description="Discovers hidden parameters via diff-based brute-force (arjun-style)",
        produces=["discovered_params"],
        timeout=60.0,
    )

    async def run(self, target: Target, ctx) -> PluginResult:
        if ctx.http is None:
            return PluginResult.fail(
                self.meta.name, target.host, error="HTTP client not available"
            )

        from basilisk.utils.http_check import resolve_base_url

        findings: list[Finding] = []
        all_discovered: list[dict] = []

        base_url = await resolve_base_url(target.host, ctx)
        if not base_url:
            return PluginResult.success(
                self.meta.name, target.host,
                findings=[Finding.info("Host not reachable")],
                data={"discovered_params": []},
            )

        # Collect scan paths
        scan_paths = ["/"]

        # Add paths from OpenAPI spec if available
        api_endpoints = ctx.state.get("api_endpoints_detailed", {}).get(target.host, [])
        for ep in api_endpoints:
            if ep["path"] not in scan_paths:
                scan_paths.append(ep["path"])

        # Add paths from dir_brute/web_crawler
        extra_paths = ctx.state.get("discovered_api_paths", {}).get(target.host, [])
        for p in extra_paths:
            if p not in scan_paths:
                scan_paths.append(p)

        # Limit to top paths
        scan_paths = scan_paths[:10]

        # Build candidate param list
        candidates = list(COMMON_PARAMS)

        # Mine params from HTML/JS (if web_crawler ran)
        mined = await self._mine_params_from_page(ctx, base_url)
        for p in mined:
            if p not in candidates:
                candidates.append(p)

        # Add params from OpenAPI spec
        for ep in api_endpoints:
            for p in ep.get("parameters", []):
                name = p.get("name", "")
                if name and name not in candidates:
                    candidates.append(name)

        # Add params from link_extractor
        for p in ctx.state.get("link_params", []):
            if p not in candidates:
                candidates.append(p)

        for path in scan_paths:
            if ctx.should_stop or len(all_discovered) >= MAX_FOUND:
                break

            url = f"{base_url}{path}"
            discovered = await self._discover_params(ctx, url, candidates)

            for param_info in discovered:
                param_info["path"] = path
                all_discovered.append(param_info)

        # Generate findings
        if all_discovered:
            # Group by significance
            significant = [d for d in all_discovered if d.get("significant")]
            reflective = [d for d in all_discovered if d.get("reflected")]

            if reflective:
                findings.append(Finding.medium(
                    f"Reflective hidden parameters: "
                    f"{', '.join(d['name'] for d in reflective[:10])}",
                    description=(
                        "These parameters reflect input in the response, "
                        "potential injection points"
                    ),
                    evidence="; ".join(
                        f"{d['path']}?{d['name']} (delta={d.get('score', 0):.2f})"
                        for d in reflective[:10]
                    ),
                    remediation="Review all discovered parameters for injection vulnerabilities",
                    tags=["pentesting", "param-discovery"],
                ))

            if significant:
                findings.append(Finding.low(
                    f"Hidden parameters discovered: "
                    f"{', '.join(d['name'] for d in significant[:15])}",
                    description=(
                        "These parameters affect server response "
                        "(status, length, or content change)"
                    ),
                    evidence="; ".join(
                        f"{d['path']}?{d['name']} (delta={d.get('score', 0):.2f})"
                        for d in significant[:15]
                    ),
                    tags=["pentesting", "param-discovery"],
                ))

            # Store in ctx.state for other plugins to use
            discovered_params = ctx.state.setdefault("discovered_params", {})
            host_params = discovered_params.setdefault(target.host, {})
            for d in all_discovered:
                path = d["path"]
                if path not in host_params:
                    host_params[path] = []
                host_params[path].append(d["name"])

        if not findings:
            findings.append(Finding.info(
                f"No hidden parameters discovered on {len(scan_paths)} paths",
                tags=["pentesting", "param-discovery"],
            ))

        return PluginResult.success(
            self.meta.name, target.host,
            findings=findings,
            data={
                "discovered_params": all_discovered,
                "paths_scanned": len(scan_paths),
                "candidates_tested": len(candidates),
            },
        )

    async def _discover_params(
        self,
        ctx,
        url: str,
        candidates: list[str],
    ) -> list[dict]:
        """Diff-based parameter discovery for a single URL."""
        differ = ctx.differ
        if differ is None:
            return []

        # Capture baseline
        try:
            async with ctx.rate:
                resp = await ctx.http.get(url, timeout=8.0)
                baseline_body = await resp.text(encoding="utf-8", errors="replace")
                baseline = differ.capture(
                    resp.status,
                    dict(resp.headers),
                    baseline_body,
                )
        except Exception:
            return []

        # Test a random canary first to establish noise floor
        canary_name = "bsk_canary_9x7z"
        canary_value = "basilisk_test_12345"
        try:
            async with ctx.rate:
                resp = await ctx.http.get(
                    f"{url}?{canary_name}={canary_value}", timeout=8.0,
                )
                canary_body = await resp.text(encoding="utf-8", errors="replace")
                canary_snap = differ.capture(
                    resp.status, dict(resp.headers), canary_body,
                )
                noise = differ.compare(baseline, canary_snap)
                noise_score = noise.score
        except Exception:
            noise_score = 0.0

        discovered: list[dict] = []
        test_value = "basilisk7x3s"

        for i in range(0, len(candidates), BATCH_SIZE):
            if ctx.should_stop or len(discovered) >= MAX_FOUND:
                break

            batch = candidates[i:i + BATCH_SIZE]

            for param in batch:
                if ctx.should_stop:
                    break

                try:
                    test_url = f"{url}?{param}={test_value}"
                    async with ctx.rate:
                        resp = await ctx.http.get(test_url, timeout=5.0)
                        body = await resp.text(encoding="utf-8", errors="replace")
                        snap = differ.capture(
                            resp.status, dict(resp.headers), body,
                        )

                    result = differ.compare(baseline, snap)

                    # Parameter is interesting if it causes more change than noise
                    is_significant = result.score > max(noise_score + 0.05, 0.10)
                    is_reflected = test_value in body and test_value not in baseline_body

                    if is_significant or is_reflected:
                        discovered.append({
                            "name": param,
                            "score": round(result.score, 3),
                            "status_changed": result.status_changed,
                            "length_delta": result.length_delta,
                            "significant": is_significant,
                            "reflected": is_reflected,
                        })

                except Exception:
                    continue

        return discovered

    async def _mine_params_from_page(
        self, ctx, base_url: str,
    ) -> list[str]:
        """Extract potential parameter names from page HTML/JS."""
        mined: set[str] = set()

        try:
            async with ctx.rate:
                resp = await ctx.http.get(base_url, timeout=8.0)
                body = await resp.text(encoding="utf-8", errors="replace")
        except Exception:
            return []

        # From HTML form inputs
        for m in re.finditer(r'name\s*=\s*["\']([a-zA-Z_][\w.-]{0,50})["\']', body):
            mined.add(m.group(1))

        # From URL query strings in links
        for m in re.finditer(r'[?&]([a-zA-Z_][\w.-]{0,50})=', body):
            mined.add(m.group(1))

        # From JavaScript variable assignments
        for m in re.finditer(r'(?:var|let|const)\s+(\w{2,30})\s*=', body):
            mined.add(m.group(1))

        # From JS object keys (potential API params)
        for m in re.finditer(r'["\']([\w]{2,30})["\']\s*:', body):
            mined.add(m.group(1))

        # From HTML data attributes
        for m in re.finditer(r'data-([\w-]{2,30})', body):
            mined.add(m.group(1).replace("-", "_"))

        # From fetch/ajax URLs
        for m in re.finditer(r'(?:fetch|axios|ajax)\s*\(["\']([^"\']+)', body):
            url_str = m.group(1)
            for pm in re.finditer(r'[?&]([a-zA-Z_]\w{0,30})=', url_str):
                mined.add(pm.group(1))

        # Filter out common noise
        noise = {
            "class", "style", "type", "value", "href", "src", "alt",
            "title", "width", "height", "for", "method", "charset",
            "content", "rel", "http", "https", "true", "false",
            "null", "undefined", "function", "return", "var", "let",
            "const", "new", "this", "document", "window",
        }
        return [p for p in mined if p.lower() not in noise and len(p) > 1]
