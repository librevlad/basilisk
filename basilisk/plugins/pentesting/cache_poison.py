"""Web cache poisoning detection via unkeyed headers — CDN-specific techniques.

Tests unkeyed headers (X-Forwarded-Host/Scheme/URL/Port, X-Host, etc.),
CDN-specific techniques, cache key discovery, path normalization exploits.
"""

from __future__ import annotations

import hashlib
import logging
import time
from typing import ClassVar

from basilisk.core.plugin import BasePlugin, PluginCategory, PluginMeta
from basilisk.models.result import Finding, PluginResult
from basilisk.models.target import Target

logger = logging.getLogger(__name__)

# ── Unkeyed headers to test ────────────────────────────────────────────
POISON_HEADERS = [
    # Host override
    ("X-Forwarded-Host", "basilisk-cache-{nonce}.example.com"),
    ("X-Host", "basilisk-cache-{nonce}.example.com"),
    ("X-Forwarded-Server", "basilisk-cache-{nonce}"),
    ("Forwarded", "host=basilisk-cache-{nonce}.example.com"),
    # URL override
    ("X-Original-URL", "/basilisk-cache-{nonce}"),
    ("X-Rewrite-URL", "/basilisk-cache-{nonce}"),
    # Scheme / protocol override
    ("X-Forwarded-Scheme", "nothttps"),
    ("X-Forwarded-Proto", "nothttps"),
    ("X-Forwarded-SSL", "off"),
    # Port override
    ("X-Forwarded-Port", "1337"),
    # Other
    ("X-HTTP-Method-Override", "POST"),
    ("X-Forwarded-For", "127.0.0.1"),
    ("True-Client-IP", "127.0.0.1"),
    ("CF-Connecting-IP", "127.0.0.1"),
    ("X-Real-IP", "127.0.0.1"),
    ("X-Custom-IP-Authorization", "127.0.0.1"),
    # Path normalization
    ("X-Original-Url", "/admin"),
    ("X-Rewrite-Url", "/admin"),
]

# ── Cache indicator headers ────────────────────────────────────────────
CACHE_INDICATORS = [
    "x-cache", "cf-cache-status", "age", "x-cache-status",
    "x-varnish", "x-proxy-cache", "x-cdn", "via",
    "x-fastly-request-id", "x-served-by", "x-cache-hits",
    "x-edge-location", "x-amz-cf-pop", "x-cdn-geo",
    "x-akamai-request-id", "x-cache-key",
    "x-iinfo",  # Incapsula
]

CACHE_HIT_VALUES = [
    "hit", "hit,", "tcp_hit", "mem_hit",
    "hit from cloudfront", "hit from cdn",
]

SCAN_PAGES = [
    "/", "/index.html", "/robots.txt",
    "/static/", "/about", "/favicon.ico",
    "/assets/", "/css/", "/js/",
]


class CachePoisonPlugin(BasePlugin):
    meta: ClassVar[PluginMeta] = PluginMeta(
        name="cache_poison",
        display_name="Cache Poisoning Scanner",
        category=PluginCategory.PENTESTING,
        description=(
            f"Detects web cache poisoning via {len(POISON_HEADERS)} unkeyed headers, "
            "CDN-specific techniques, path normalization exploits"
        ),
        produces=["cache_poison_findings"],
        timeout=30.0,
    )

    async def run(self, target: Target, ctx) -> PluginResult:
        if ctx.http is None:
            return PluginResult.fail(
                self.meta.name, target.host, error="HTTP client not available",
            )

        from basilisk.utils.http_check import resolve_base_url

        findings: list[Finding] = []
        tested: list[dict] = []

        base_url = await resolve_base_url(target.host, ctx)
        if not base_url:
            return PluginResult.success(
                self.meta.name, target.host,
                findings=[Finding.info("Host not reachable")],
                data={"cache_poison_tests": []},
            )

        nonce = hashlib.md5(
            f"{target.host}{time.time()}".encode(),
        ).hexdigest()[:8]

        for page in SCAN_PAGES:
            if ctx.should_stop:
                break
            url = f"{base_url}{page}"

            # Step 1: Check if page is cached
            cache_info = await self._check_cache(ctx, url)
            if not cache_info["cached"]:
                continue

            # Step 2: Get baseline
            baseline_body, baseline_headers = await self._get_baseline(ctx, url)
            if baseline_body is None:
                continue

            # Step 3: Test each poison header
            for header_name, header_template in POISON_HEADERS:
                if ctx.should_stop:
                    break

                header_value = header_template.replace("{nonce}", nonce)
                result = await self._test_header(
                    ctx, url, header_name, header_value,
                    baseline_body, baseline_headers,
                )

                if result["reflected_in_body"] or result["reflected_in_headers"]:
                    reflection = result["reflection_detail"]
                    tested.append({
                        "page": page, "header": header_name,
                        "reflected_in": reflection, "cache_present": True,
                    })

                    # Check if cache is storing the poisoned response
                    cache_poisoned = await self._verify_cache_poison(
                        ctx, url, header_name, header_value,
                    )

                    severity = Finding.critical if cache_poisoned else Finding.high
                    desc_suffix = (
                        " Cache confirmed storing poisoned response!"
                        if cache_poisoned else ""
                    )

                    findings.append(severity(
                        f"Cache poisoning: {header_name} reflected on {page}",
                        description=(
                            f"Unkeyed header '{header_name}' reflected in "
                            f"response ({reflection}) on cached page.{desc_suffix}"
                        ),
                        evidence=(
                            f"URL: {url}\n"
                            f"Header: {header_name}: {header_value}\n"
                            f"Reflected in: {reflection}\n"
                            f"Cache: {cache_info['type']}\n"
                            f"Cache poisoned: {cache_poisoned}"
                        ),
                        remediation=(
                            "Include all client-controlled headers in cache key, "
                            "or strip unrecognized headers at the edge. "
                            "Use Vary header for relevant request headers."
                        ),
                        tags=["pentesting", "cache-poisoning"],
                    ))

                # URL override check (path override)
                if (
                    header_name in ("X-Original-URL", "X-Rewrite-URL")
                    and result.get("status_changed")
                ):
                    tested.append({
                        "page": page, "header": header_name,
                        "status_change": result["new_status"],
                    })
                    findings.append(Finding.medium(
                        f"URL override: {header_name} affects routing on {page}",
                        description=(
                            f"'{header_name}' changed response status to "
                            f"{result['new_status']} — server uses this for routing"
                        ),
                        evidence=f"URL: {url}\n{header_name}: {header_value}",
                        remediation=f"Strip {header_name} header at the proxy",
                        tags=["pentesting", "cache-poisoning", "url-override"],
                    ))

        # Phase 2: Path normalization tests
        if not findings and not ctx.should_stop:
            await self._check_path_normalization(
                ctx, base_url, nonce, findings, tested,
            )

        if not findings:
            findings.append(Finding.info(
                "No web cache poisoning vulnerabilities detected",
                tags=["pentesting", "cache-poisoning"],
            ))

        return PluginResult.success(
            self.meta.name, target.host,
            findings=findings,
            data={"cache_poison_tests": tested},
        )

    # ── Helpers ─────────────────────────────────────────────────────────

    async def _check_cache(self, ctx, url: str) -> dict:
        """Determine if a page is cached and identify cache type."""
        try:
            async with ctx.rate:
                resp = await ctx.http.get(url, timeout=8.0)
                headers_lower = {k.lower(): v for k, v in resp.headers.items()}

                cached = False
                cache_type = "unknown"

                for indicator in CACHE_INDICATORS:
                    if indicator in headers_lower:
                        cached = True
                        val = headers_lower[indicator].lower()
                        if any(hit in val for hit in CACHE_HIT_VALUES):
                            cached = True
                        if "cloudflare" in val or "cf-" in indicator:
                            cache_type = "Cloudflare"
                        elif "varnish" in val:
                            cache_type = "Varnish"
                        elif "fastly" in val or "x-fastly" in indicator:
                            cache_type = "Fastly"
                        elif "cloudfront" in val or "amz" in indicator:
                            cache_type = "CloudFront"
                        elif "akamai" in val:
                            cache_type = "Akamai"

                # Check Cache-Control
                cc = headers_lower.get("cache-control", "")
                if "public" in cc or "max-age" in cc or "s-maxage" in cc:
                    cached = True

                return {"cached": cached, "type": cache_type}
        except Exception as e:
            logger.debug("cache_poison: %s", e)
            return {"cached": False, "type": "unknown"}

    async def _get_baseline(self, ctx, url: str) -> tuple:
        try:
            async with ctx.rate:
                resp = await ctx.http.get(url, timeout=8.0)
                body = await resp.text(encoding="utf-8", errors="replace")
                return body, dict(resp.headers)
        except Exception as e:
            logger.debug("cache_poison: %s", e)
            return None, None

    async def _test_header(
        self, ctx, url: str, hdr_name: str, hdr_value: str,
        baseline_body: str, baseline_headers: dict,
    ) -> dict:
        result = {
            "reflected_in_body": False,
            "reflected_in_headers": False,
            "reflection_detail": "",
            "status_changed": False,
            "new_status": 0,
        }
        try:
            async with ctx.rate:
                resp = await ctx.http.get(
                    url, headers={hdr_name: hdr_value}, timeout=8.0,
                )
                body = await resp.text(encoding="utf-8", errors="replace")

            # Check body reflection
            if hdr_value in body and hdr_value not in baseline_body:
                result["reflected_in_body"] = True
                result["reflection_detail"] = "Response body"

            # Check header reflection
            for rh_name, rh_value in resp.headers.items():
                if hdr_value in str(rh_value):
                    base_val = baseline_headers.get(rh_name, "")
                    if hdr_value not in str(base_val):
                        result["reflected_in_headers"] = True
                        result["reflection_detail"] = f"Header: {rh_name}"
                        break

            if resp.status != 200 and hdr_name in ("X-Original-URL", "X-Rewrite-URL"):
                result["status_changed"] = True
                result["new_status"] = resp.status

        except Exception as e:
            logger.debug("cache_poison: %s", e)
        return result

    async def _verify_cache_poison(
        self, ctx, url: str, hdr_name: str, hdr_value: str,
    ) -> bool:
        """Check if the poisoned response was cached by making a clean request."""
        try:
            # First, send the poison request
            async with ctx.rate:
                await ctx.http.get(
                    url, headers={hdr_name: hdr_value}, timeout=8.0,
                )

            # Then make a clean request to see if cached response is poisoned
            import asyncio
            await asyncio.sleep(0.5)

            async with ctx.rate:
                resp = await ctx.http.get(url, timeout=8.0)
                body = await resp.text(encoding="utf-8", errors="replace")
                return hdr_value in body

        except Exception as e:
            logger.debug("cache_poison: %s", e)
            return False

    async def _check_path_normalization(
        self, ctx, base_url: str, nonce: str,
        findings: list[Finding], tested: list[dict],
    ) -> None:
        """Test cache key normalization differences."""
        norm_tests = [
            ("/./", "dot-segment"),
            ("/%2e/", "encoded-dot"),
            ("/;/", "semicolon"),
            ("//", "double-slash"),
            ("/%00/", "null-byte"),
        ]

        for path_variant, label in norm_tests:
            if ctx.should_stop:
                break
            url1 = f"{base_url}/"
            url2 = f"{base_url}{path_variant}"

            try:
                async with ctx.rate:
                    resp1 = await ctx.http.get(url1, timeout=5.0)
                    body1 = await resp1.text(encoding="utf-8", errors="replace")

                async with ctx.rate:
                    resp2 = await ctx.http.get(url2, timeout=5.0)
                    body2 = await resp2.text(encoding="utf-8", errors="replace")

                # If both return same content but paths differ,
                # cache might key differently
                if (
                    resp1.status == resp2.status == 200
                    and abs(len(body1) - len(body2)) < 50
                    and body1[:200] == body2[:200]
                ):
                    tested.append({
                        "type": "path_normalization",
                        "variant": label,
                        "same_response": True,
                    })
            except Exception as e:
                logger.debug("cache_poison: %s", e)
                continue
